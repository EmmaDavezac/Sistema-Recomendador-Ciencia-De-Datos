{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Entendimiento del Negocio\n",
    "## Objetivo de Negocio\n",
    "El principal objetivo del negocio, es aumentar las ganancias por ventas en un 10% para el año 2026, en contraste con lo vendido en 2025.\n",
    "\n",
    "## Problema\n",
    "El sistema actual muestra artículos aleatorios en un carrusel. Se necesita diseñar e implementar un Sistema Recomendador que sugiera ítems de interés para cada usuario, reemplazando la lógica aleatoria por una predictiva. Esto busca mejorar la experiencia del usuario y, consecuentemente, aumentar la tasa de conversión y el volumen de ventas, alineándose con el objetivo de negocio.\n",
    "\n",
    "## Consideraciones\n",
    "\n",
    "* **Items Fijos:** El comitente solo vende 100 artículos y no se agregarán ítems nuevos (\"por cábala siempre vende 100\").Por lo que la cantidad de items es fija.\n",
    "* **Usuarios Nuevos:** La plataforma recibe \"muchos usuarios nuevos todo el tiempo\", lo que obliga a tener una estrategia robusta de recomendación inicial (Cold Start).\n",
    "* **Volumen de Compra:** Los usuarios compran en promedio 7 u 8 artículos, a lo mucho 10.\n",
    "* **Ausencia de Datos:** No existe una base de datos preexistente, por lo que se debe diseñar e implementar una para almacenar usuarios, ítems y preferencias.\n",
    "* **Items Genericos:** El comitente no nos especifica los items, los deja a nuestra interpretación, siempre que el sistema funciona"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.Entendimiento de los datos\n",
    "## Datos a Almacenar\n",
    "Dado que no hay una base de datos existente, debemos diseñar una que modele las entidades y relaciones del sistema.\n",
    "Debemos almacenar:\n",
    "* **Usuarios:** En la documentación de la API suministrada por el comitente se espeficifica que debe tener los atributos:\n",
    "    * *id* que es el identificador de tipo *integer*\n",
    "    * *username* que es el nombre de usuario de tipo *string*\n",
    "    `ejemplo: pepitaLaPistolera`\n",
    "    * *attributes* de tipo *object* que almacena atributos de forma dinamica.\n",
    "    `ejemplo: {\n",
    "        'campo1': 'valor1',\n",
    "        'campo2': 'valor2'\n",
    "        }`\n",
    "* **Items:** En la documentación suministrada por el comitente se espeficifica que siempre habra exactamente 100 items y que cada uno debe tener los atributos:\n",
    "    * *id* que es el identificador de tipo *integer*\n",
    "    * *name* que es el nombre del item de tipo *string*\n",
    "    `ejemplo: Las mil y una noches`\n",
    "    * *attributes* de tipo *object* que almacena atributos de forma dinamica.\n",
    "    `ejemplo: {\n",
    "        'campo1': 'valor1',\n",
    "        'campo2': 'valor2'\n",
    "        }`\n",
    "* **Preferencias de los usuarios por los items:** El comitente nos deja este apartado a nuestro parecer. Diseñamos almacerlas en una entidad llamada \"Preferences\", que registra el rating que le da un usuario a un item que compro\", que almacene los atributos:\n",
    "    * *user_id* que es el identificador del usuario de tipo *integer*\n",
    "    * *item_id* que es el identificador del item de tipo *integer*\n",
    "    * *preference_value*: la ponderación (rating) que le da un usuario al item que compro. Es de tipo *integer* y tiene un valor entre 1 y 5. Luego de comprar un item, el usuario lo reseña indicando que le parecio el item a traves de estrellas, como lo hacen plataformas parecias como Mercado Libre.\n",
    "\n",
    "## Implementación de la persistencia de datos\n",
    "Se diseñó una base de datos SQLite (*recommendation_system.db*) para almacenar las tres entidades principales del sistema.\n",
    "Las razones principales por la que elegimos SQLite en lugar sobre otras opciones son su ligereza, portabilidad y facilidad de uso, ya que no requiere un servidor, se ejecuta como una biblioteca en el mismo proceso de la aplicación, almacena la base de datos en un único archivo, y es ideal para prototipos o para ejecutar localmente sin conexión a internet.\n",
    "\n",
    "### Codigo SQL para la creacion de las tablas\n",
    "**Tabla users**\n",
    " ```SQL\n",
    " CREATE TABLE IF NOT EXISTS users (\n",
    "                id INTEGER PRIMARY KEY NOT NULL,\n",
    "                username TEXT UNIQUE NOT NULL,\n",
    "                attributes TEXT\n",
    "            );\n",
    " ```\n",
    "**Tabla items**\n",
    " ```SQL\n",
    "CREATE TABLE IF NOT EXISTS items (\n",
    "                    item_id INTEGER PRIMARY KEY NOT NULL,\n",
    "                    name TEXT NOT NULL,\n",
    "                    attributes TEXT\n",
    "                );\n",
    " ```\n",
    " **Tabla preferences**\n",
    " ```SQL\n",
    " CREATE TABLE IF NOT EXISTS preferences (\n",
    "                user_id INTEGER NOT NULL,\n",
    "                item_id INTEGER NOT NULL,\n",
    "                preference_value INTEGER NOT NULL,\n",
    "                PRIMARY KEY (user_id, item_id),\n",
    "                FOREIGN KEY(user_id) REFERENCES users(id) ON DELETE CASCADE,\n",
    "                FOREIGN KEY(item_id) REFERENCES items(item_id) ON DELETE CASCADE\n",
    "            );\n",
    "\n",
    " ```\n",
    "### Prevención ante valores perdidos\n",
    "Prevenimos valores perdidos mediante al momento de crear la base de datos utilizano los constraint:\n",
    "* **NOT NULL**: Es para evitar que datos importantes tomen el valor *null*.\n",
    "* **ON DELETE CASCADE**: Es para no tener preferencias con referencias nulas que generen inconsistencias en el modelo. Al eliminarse un usuario, se eliminan todas las preferencias de este.\n",
    "\n",
    "### Generación de los datos iniciales\n",
    "Generamos un dataset inicial para demostración de la aplicación respetando las consideraciones expresadas por el comitente. \n",
    "Utilizamos la integencia artificial Gemini para generar 700 Usuarios, 100 Items y aproximadamente 5600 Preferencias. Estos datos fueron almacenados en formato *.csv* en los archivos:\n",
    "* **Items.csv:** El archivo tiene el formato interno\n",
    "```csv\n",
    "item_id,name,price,category\n",
    "1,Crónicas de la Sombra,15.99,Ficción Fantástica\n",
    "```\n",
    "* **Preferences.csv:** El archivo tiene el formato interno\n",
    "```csv\n",
    "user_id,item_id,preference_value,interaction_date\n",
    "1,55,4,12/1/2025\n",
    "```\n",
    "* **Users.csv:** El archivo tiene el formato interno\n",
    "```csv\n",
    "item_id,name,price,category\n",
    "1,Crónicas de la Sombra,15.99,Ficción Fantástica\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Preparación de los Datos\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cargamos los datos desde los CSVs usando la libreria Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "USERS_URL = './Datasets/Users.csv'# Ruta local del archivo CSV de usuarios\n",
    "ITEMS_URL = './Datasets/Items.csv'# Ruta local del archivo CSV de items\n",
    "PREFERENCES_URL = './Datasets/Preferences.csv'# Ruta local del archivo CSV de preferencias\n",
    "users_df = pd.read_csv(USERS_URL)\n",
    "items_df = pd.read_csv(ITEMS_URL)\n",
    "preferences_df = pd.read_csv(PREFERENCES_URL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocesamos los atributos de USERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "if 'id' not in users_df.columns: \n",
    "    id_cols = [col for col in users_df.columns if 'id' in col.lower()]\n",
    "    if id_cols:\n",
    "        users_df = users_df.rename(columns={id_cols[0]: 'id'})\n",
    "\n",
    "BASE_KEYS = ['id', 'username']\n",
    "# Función para serializar atributos adicionales a JSON\n",
    "def serialize_attributes(row):\n",
    "    attributes = {\n",
    "        k: v for k, v in row.items() \n",
    "        if k not in BASE_KEYS and pd.notna(v)\n",
    "    }\n",
    "    return json.dumps(attributes)# Serializamos a JSON\n",
    "\n",
    "users_df['attributes'] = users_df.apply(serialize_attributes, axis=1)# Creamos la columna 'attributes' con JSON\n",
    "users_df_clean = users_df[BASE_KEYS + ['attributes']].copy()# Filtramos solo las columnas necesarias        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocesamiento de ITEMS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if 'id' in items_df.columns and 'item_id' not in items_df.columns:\n",
    "    items_df.rename(columns={'id': 'item_id'}, inplace=True)\n",
    "    \n",
    "BASE_ITEM_KEYS = ['item_id', 'name']\n",
    "def serialize_item_attributes(row):\n",
    "    attributes = {\n",
    "        k: v for k, v in row.items() \n",
    "        if k not in BASE_ITEM_KEYS and pd.notna(v)\n",
    "    }\n",
    "    return json.dumps(attributes)\n",
    "\n",
    "items_df['attributes'] = items_df.apply(serialize_item_attributes, axis=1)\n",
    "items_df_clean = items_df[BASE_ITEM_KEYS + ['attributes']].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocesamiento de PREFERENCES "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mapeo y Filtrado de PREFERENCES \n",
    "# Aseguramos que las columnas tengan los nombres correctos\n",
    "preferences_df.rename(columns={\n",
    "    'user_id': 'user_id',\n",
    "    'item_id': 'item_id',\n",
    "    'preference_value': 'preference_value'\n",
    "}, inplace=True)\n",
    "\n",
    "# Filtramos solo las columnas necesarias \n",
    "preferences_df = preferences_df[['user_id', 'item_id', 'preference_value']].copy()\n",
    "\n",
    "# Aseguramos que ITEMS tenga 'item_id'\n",
    "# Asumiendo que el CSV de Items usa 'item_id'\n",
    "if 'id' in items_df.columns and 'item_id' not in items_df.columns:\n",
    "    items_df.rename(columns={'id': 'item_id'}, inplace=True)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una vez preprocesados los csv, creamos la base de datos con el formato que se indicado en la fase anterior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Error al inicializar SQLite: UNIQUE constraint failed: users.id\n"
     ]
    },
    {
     "ename": "IntegrityError",
     "evalue": "UNIQUE constraint failed: users.id",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mIntegrityError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[253]\u001b[39m\u001b[32m, line 41\u001b[39m\n\u001b[32m     38\u001b[39m conn.execute(\u001b[33m\"\u001b[39m\u001b[33mPRAGMA foreign_keys = OFF;\u001b[39m\u001b[33m\"\u001b[39m) \n\u001b[32m     40\u001b[39m \u001b[38;5;66;03m# Insertamos los datos en las tablas correspondientes\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m41\u001b[39m \u001b[43musers_df_clean\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto_sql\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43musers\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mif_exists\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mappend\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m     42\u001b[39m items_df_clean.to_sql(\u001b[33m'\u001b[39m\u001b[33mitems\u001b[39m\u001b[33m'\u001b[39m, conn, if_exists=\u001b[33m'\u001b[39m\u001b[33mappend\u001b[39m\u001b[33m'\u001b[39m, index=\u001b[38;5;28;01mFalse\u001b[39;00m) \n\u001b[32m     43\u001b[39m preferences_df.to_sql(\u001b[33m'\u001b[39m\u001b[33mpreferences\u001b[39m\u001b[33m'\u001b[39m, conn, if_exists=\u001b[33m'\u001b[39m\u001b[33mappend\u001b[39m\u001b[33m'\u001b[39m, index=\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Emma\\Desktop\\Sistema-Recomendador-Ciencia-De-Datos\\venv\\Lib\\site-packages\\pandas\\util\\_decorators.py:333\u001b[39m, in \u001b[36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    327\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) > num_allow_args:\n\u001b[32m    328\u001b[39m     warnings.warn(\n\u001b[32m    329\u001b[39m         msg.format(arguments=_format_argument_list(allow_args)),\n\u001b[32m    330\u001b[39m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[32m    331\u001b[39m         stacklevel=find_stack_level(),\n\u001b[32m    332\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m333\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Emma\\Desktop\\Sistema-Recomendador-Ciencia-De-Datos\\venv\\Lib\\site-packages\\pandas\\core\\generic.py:3109\u001b[39m, in \u001b[36mNDFrame.to_sql\u001b[39m\u001b[34m(self, name, con, schema, if_exists, index, index_label, chunksize, dtype, method)\u001b[39m\n\u001b[32m   2911\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   2912\u001b[39m \u001b[33;03mWrite records stored in a DataFrame to a SQL database.\u001b[39;00m\n\u001b[32m   2913\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m   3105\u001b[39m \u001b[33;03m[(1,), (None,), (2,)]\u001b[39;00m\n\u001b[32m   3106\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m  \u001b[38;5;66;03m# noqa: E501\u001b[39;00m\n\u001b[32m   3107\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mio\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m sql\n\u001b[32m-> \u001b[39m\u001b[32m3109\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msql\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto_sql\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   3110\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   3111\u001b[39m \u001b[43m    \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3112\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcon\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3113\u001b[39m \u001b[43m    \u001b[49m\u001b[43mschema\u001b[49m\u001b[43m=\u001b[49m\u001b[43mschema\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3114\u001b[39m \u001b[43m    \u001b[49m\u001b[43mif_exists\u001b[49m\u001b[43m=\u001b[49m\u001b[43mif_exists\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3115\u001b[39m \u001b[43m    \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m=\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3116\u001b[39m \u001b[43m    \u001b[49m\u001b[43mindex_label\u001b[49m\u001b[43m=\u001b[49m\u001b[43mindex_label\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3117\u001b[39m \u001b[43m    \u001b[49m\u001b[43mchunksize\u001b[49m\u001b[43m=\u001b[49m\u001b[43mchunksize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3118\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3119\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3120\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Emma\\Desktop\\Sistema-Recomendador-Ciencia-De-Datos\\venv\\Lib\\site-packages\\pandas\\io\\sql.py:844\u001b[39m, in \u001b[36mto_sql\u001b[39m\u001b[34m(frame, name, con, schema, if_exists, index, index_label, chunksize, dtype, method, engine, **engine_kwargs)\u001b[39m\n\u001b[32m    839\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(\n\u001b[32m    840\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m'\u001b[39m\u001b[33mframe\u001b[39m\u001b[33m'\u001b[39m\u001b[33m argument should be either a Series or a DataFrame\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    841\u001b[39m     )\n\u001b[32m    843\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m pandasSQL_builder(con, schema=schema, need_transaction=\u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m pandas_sql:\n\u001b[32m--> \u001b[39m\u001b[32m844\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mpandas_sql\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto_sql\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    845\u001b[39m \u001b[43m        \u001b[49m\u001b[43mframe\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    846\u001b[39m \u001b[43m        \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    847\u001b[39m \u001b[43m        \u001b[49m\u001b[43mif_exists\u001b[49m\u001b[43m=\u001b[49m\u001b[43mif_exists\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    848\u001b[39m \u001b[43m        \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m=\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    849\u001b[39m \u001b[43m        \u001b[49m\u001b[43mindex_label\u001b[49m\u001b[43m=\u001b[49m\u001b[43mindex_label\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    850\u001b[39m \u001b[43m        \u001b[49m\u001b[43mschema\u001b[49m\u001b[43m=\u001b[49m\u001b[43mschema\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    851\u001b[39m \u001b[43m        \u001b[49m\u001b[43mchunksize\u001b[49m\u001b[43m=\u001b[49m\u001b[43mchunksize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    852\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    853\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    854\u001b[39m \u001b[43m        \u001b[49m\u001b[43mengine\u001b[49m\u001b[43m=\u001b[49m\u001b[43mengine\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    855\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mengine_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    856\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Emma\\Desktop\\Sistema-Recomendador-Ciencia-De-Datos\\venv\\Lib\\site-packages\\pandas\\io\\sql.py:2841\u001b[39m, in \u001b[36mSQLiteDatabase.to_sql\u001b[39m\u001b[34m(self, frame, name, if_exists, index, index_label, schema, chunksize, dtype, method, engine, **engine_kwargs)\u001b[39m\n\u001b[32m   2831\u001b[39m table = SQLiteTable(\n\u001b[32m   2832\u001b[39m     name,\n\u001b[32m   2833\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   2838\u001b[39m     dtype=dtype,\n\u001b[32m   2839\u001b[39m )\n\u001b[32m   2840\u001b[39m table.create()\n\u001b[32m-> \u001b[39m\u001b[32m2841\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtable\u001b[49m\u001b[43m.\u001b[49m\u001b[43minsert\u001b[49m\u001b[43m(\u001b[49m\u001b[43mchunksize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Emma\\Desktop\\Sistema-Recomendador-Ciencia-De-Datos\\venv\\Lib\\site-packages\\pandas\\io\\sql.py:1121\u001b[39m, in \u001b[36mSQLTable.insert\u001b[39m\u001b[34m(self, chunksize, method)\u001b[39m\n\u001b[32m   1118\u001b[39m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m   1120\u001b[39m chunk_iter = \u001b[38;5;28mzip\u001b[39m(*(arr[start_i:end_i] \u001b[38;5;28;01mfor\u001b[39;00m arr \u001b[38;5;129;01min\u001b[39;00m data_list))\n\u001b[32m-> \u001b[39m\u001b[32m1121\u001b[39m num_inserted = \u001b[43mexec_insert\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeys\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchunk_iter\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1122\u001b[39m \u001b[38;5;66;03m# GH 46891\u001b[39;00m\n\u001b[32m   1123\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m num_inserted \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Emma\\Desktop\\Sistema-Recomendador-Ciencia-De-Datos\\venv\\Lib\\site-packages\\pandas\\io\\sql.py:2537\u001b[39m, in \u001b[36mSQLiteTable._execute_insert\u001b[39m\u001b[34m(self, conn, keys, data_iter)\u001b[39m\n\u001b[32m   2535\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_execute_insert\u001b[39m(\u001b[38;5;28mself\u001b[39m, conn, keys, data_iter) -> \u001b[38;5;28mint\u001b[39m:\n\u001b[32m   2536\u001b[39m     data_list = \u001b[38;5;28mlist\u001b[39m(data_iter)\n\u001b[32m-> \u001b[39m\u001b[32m2537\u001b[39m     \u001b[43mconn\u001b[49m\u001b[43m.\u001b[49m\u001b[43mexecutemany\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43minsert_statement\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnum_rows\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata_list\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2538\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m conn.rowcount\n",
      "\u001b[31mIntegrityError\u001b[39m: UNIQUE constraint failed: users.id"
     ]
    }
   ],
   "source": [
    "import sqlite3\n",
    "DB_NAME = 'recommendation_system.db'# Nombre del archivo de la base de datos SQLite\n",
    "try:\n",
    "    conn = sqlite3.connect(DB_NAME)# Conexión a la base de datos SQLite\n",
    "    cursor = conn.cursor()# Cursor para ejecutar comandos SQL\n",
    "    \n",
    "    #Creamos tabla de usuarios con id como PRIMARY KEY y username único\n",
    "    cursor.execute(\"\"\"\n",
    "            CREATE TABLE IF NOT EXISTS users (\n",
    "            id INTEGER PRIMARY KEY NOT NULL,\n",
    "            username TEXT UNIQUE NOT NULL,\n",
    "            attributes TEXT\n",
    "        );\n",
    "    \"\"\")\n",
    "    \n",
    "    # Creamos la tabla de items con item_id como PRIMARY KEY\n",
    "    cursor.execute(\"\"\"\n",
    "            CREATE TABLE IF NOT EXISTS items (\n",
    "                item_id INTEGER PRIMARY KEY NOT NULL,\n",
    "                name TEXT NOT NULL,\n",
    "                attributes TEXT\n",
    "            );\n",
    "        \"\"\")\n",
    "    \n",
    "    #Creamos la tabla de preferencias con claves foráneas a las tablas users e items y clave primaria compuesta\n",
    "    cursor.execute(\"\"\"\n",
    "        CREATE TABLE IF NOT EXISTS preferences (\n",
    "            user_id INTEGER NOT NULL,\n",
    "            item_id INTEGER NOT NULL,\n",
    "            preference_value INTEGER NOT NULL,\n",
    "            PRIMARY KEY (user_id, item_id),\n",
    "            FOREIGN KEY(user_id) REFERENCES users(id) ON DELETE CASCADE,\n",
    "            FOREIGN KEY(item_id) REFERENCES items(item_id) ON DELETE CASCADE\n",
    "        );\n",
    "    \"\"\")\n",
    "    \n",
    "    #  Deshabilitamos la verificación de FK temporalmente (solo para carga inicial) para evitar errores de inserción\n",
    "    conn.execute(\"PRAGMA foreign_keys = OFF;\") \n",
    "\n",
    "    # Insertamos los datos en las tablas correspondientes\n",
    "    users_df_clean.to_sql('users', conn, if_exists='append', index=False)\n",
    "    items_df_clean.to_sql('items', conn, if_exists='append', index=False) \n",
    "    preferences_df.to_sql('preferences', conn, if_exists='append', index=False)\n",
    "    \n",
    "    # Volvemos a habilitar la verificación de claves foráneas\n",
    "    conn.execute(\"PRAGMA foreign_keys = ON;\")\n",
    "    \n",
    "    conn.commit()# Guardamos los cambios\n",
    "    conn.close()# Cerramos la conexión\n",
    "    \n",
    "    print(f\" Base de datos SQLite creada y cargada con éxito.\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\" Error al inicializar SQLite: {e}\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verificamos que exista la base de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base de datos 'recommendation_system.db' encontrada.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import os\n",
    "if os.path.exists(DB_NAME): # Verificamos si la base de datos ya existe\n",
    "    print(f\"Base de datos '{DB_NAME}' encontrada.\")\n",
    "else:\n",
    "    print(f\"Base de datos '{DB_NAME}' no encontrada.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una vez lista la base de datos obtemos los datos desde la misma para crear las estructuras necesarias para el modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creamos un dataframe principal que contenga id_usuario, id_item, nombre del item y ranking que le dio el usuario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item_id</th>\n",
       "      <th>name</th>\n",
       "      <th>user_id</th>\n",
       "      <th>preference_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>55</td>\n",
       "      <td>Meteoritos y Cometas</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>82</td>\n",
       "      <td>Egipto Faraónico</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10</td>\n",
       "      <td>Biografía de Marie Curie</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>33</td>\n",
       "      <td>Gestión de Proyectos PMP</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>91</td>\n",
       "      <td>Robots en el Tiempo</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   item_id                      name  user_id  preference_value\n",
       "0       55      Meteoritos y Cometas        1                 4\n",
       "1       82          Egipto Faraónico        1                 4\n",
       "2       10  Biografía de Marie Curie        1                 2\n",
       "3       33  Gestión de Proyectos PMP        1                 5\n",
       "4       91       Robots en el Tiempo        1                 3"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Consulta SQL para unir items y preferences\n",
    "SQL_QUERY = \"\"\"\n",
    "SELECT \n",
    "    T1.item_id,\n",
    "    T1.name,\n",
    "    T2.user_id,\n",
    "    T2.preference_value\n",
    "FROM \n",
    "    items AS T1 \n",
    "INNER JOIN \n",
    "    preferences AS T2\n",
    "ON \n",
    "    T1.item_id = T2.item_id;\n",
    "\"\"\"\n",
    "    \n",
    "conn = sqlite3.connect(DB_NAME)# Abrimos la conexión a la base de datos\n",
    "df = pd.read_sql_query(SQL_QUERY, conn)# Leemos las preferencias uniendo items y preferences\n",
    "df.head()# Mostramos las primeras filas del DataFrame resultante"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El dataframe users_df tiene la información de los usuarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>username</th>\n",
       "      <th>attributes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>jgonzalez01@mail.com</td>\n",
       "      <td>{\"telephone\": \"11-4501-1001\", \"birthdate\": \"5/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>mrodriguez02@mail.com</td>\n",
       "      <td>{\"telephone\": \"11-4501-1002\", \"birthdate\": \"11...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>pperez03@mail.com</td>\n",
       "      <td>{\"telephone\": \"11-4501-1003\", \"birthdate\": \"3/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>llopez04@mail.com</td>\n",
       "      <td>{\"telephone\": \"11-4501-1004\", \"birthdate\": \"7/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>acarcia05@mail.com</td>\n",
       "      <td>{\"telephone\": \"11-4501-1005\", \"birthdate\": \"9/...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id               username  \\\n",
       "0   1   jgonzalez01@mail.com   \n",
       "1   2  mrodriguez02@mail.com   \n",
       "2   3      pperez03@mail.com   \n",
       "3   4      llopez04@mail.com   \n",
       "4   5     acarcia05@mail.com   \n",
       "\n",
       "                                          attributes  \n",
       "0  {\"telephone\": \"11-4501-1001\", \"birthdate\": \"5/...  \n",
       "1  {\"telephone\": \"11-4501-1002\", \"birthdate\": \"11...  \n",
       "2  {\"telephone\": \"11-4501-1003\", \"birthdate\": \"3/...  \n",
       "3  {\"telephone\": \"11-4501-1004\", \"birthdate\": \"7/...  \n",
       "4  {\"telephone\": \"11-4501-1005\", \"birthdate\": \"9/...  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "users_df = pd.read_sql_query(\"SELECT id, username, attributes FROM users\", conn)# Leemos los usuarios desde la base de datos\n",
    "users_df.head()# Mostramos las primeras filas del DataFrame de usuarios"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El dataframe users_df tiene la información de los usuarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item_id</th>\n",
       "      <th>name</th>\n",
       "      <th>attributes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Crónicas de la Sombra</td>\n",
       "      <td>{\"price\": 15.99, \"category\": \"Ficci\\u00f3n Fan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>El Jardín Silencioso</td>\n",
       "      <td>{\"price\": 22.5, \"category\": \"Novela Hist\\u00f3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Guía de Inversión Inteligente</td>\n",
       "      <td>{\"price\": 35.0, \"category\": \"Econom\\u00eda y F...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Recetas de la Abuela</td>\n",
       "      <td>{\"price\": 18.75, \"category\": \"Cocina\"}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Atlas Mundial Actualizado</td>\n",
       "      <td>{\"price\": 49.99, \"category\": \"Geograf\\u00eda\"}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   item_id                           name  \\\n",
       "0        1          Crónicas de la Sombra   \n",
       "1        2           El Jardín Silencioso   \n",
       "2        3  Guía de Inversión Inteligente   \n",
       "3        4           Recetas de la Abuela   \n",
       "4        5      Atlas Mundial Actualizado   \n",
       "\n",
       "                                          attributes  \n",
       "0  {\"price\": 15.99, \"category\": \"Ficci\\u00f3n Fan...  \n",
       "1  {\"price\": 22.5, \"category\": \"Novela Hist\\u00f3...  \n",
       "2  {\"price\": 35.0, \"category\": \"Econom\\u00eda y F...  \n",
       "3             {\"price\": 18.75, \"category\": \"Cocina\"}  \n",
       "4     {\"price\": 49.99, \"category\": \"Geograf\\u00eda\"}  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "items_df = pd.read_sql_query(\"SELECT * FROM items\", conn)# Leemos los items desde la base de datos\n",
    "items_df.head()# Mostramos las primeras filas del DataFrame de items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn.close()# Cerramos la conexión a la base de datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deserialización de los atributos del usuario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>username</th>\n",
       "      <th>attributes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>jgonzalez01@mail.com</td>\n",
       "      <td>{'telephone': '11-4501-1001', 'birthdate': '5/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>mrodriguez02@mail.com</td>\n",
       "      <td>{'telephone': '11-4501-1002', 'birthdate': '11...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>pperez03@mail.com</td>\n",
       "      <td>{'telephone': '11-4501-1003', 'birthdate': '3/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>llopez04@mail.com</td>\n",
       "      <td>{'telephone': '11-4501-1004', 'birthdate': '7/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>acarcia05@mail.com</td>\n",
       "      <td>{'telephone': '11-4501-1005', 'birthdate': '9/...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id               username  \\\n",
       "0   1   jgonzalez01@mail.com   \n",
       "1   2  mrodriguez02@mail.com   \n",
       "2   3      pperez03@mail.com   \n",
       "3   4      llopez04@mail.com   \n",
       "4   5     acarcia05@mail.com   \n",
       "\n",
       "                                          attributes  \n",
       "0  {'telephone': '11-4501-1001', 'birthdate': '5/...  \n",
       "1  {'telephone': '11-4501-1002', 'birthdate': '11...  \n",
       "2  {'telephone': '11-4501-1003', 'birthdate': '3/...  \n",
       "3  {'telephone': '11-4501-1004', 'birthdate': '7/...  \n",
       "4  {'telephone': '11-4501-1005', 'birthdate': '9/...  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if 'attributes' in users_df.columns:\n",
    "        users_df['attributes'] = users_df['attributes'].apply(\n",
    "            lambda x: json.loads(x) if pd.notna(x) and isinstance(x, str) else {}\n",
    "        )\n",
    "users_df.head()\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deserialización de los atributos del item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item_id</th>\n",
       "      <th>name</th>\n",
       "      <th>attributes</th>\n",
       "      <th>attributes_dict</th>\n",
       "      <th>price</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Crónicas de la Sombra</td>\n",
       "      <td>{\"price\": 15.99, \"category\": \"Ficci\\u00f3n Fan...</td>\n",
       "      <td>{'price': 15.99, 'category': 'Ficción Fantásti...</td>\n",
       "      <td>15.99</td>\n",
       "      <td>Ficción Fantástica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>El Jardín Silencioso</td>\n",
       "      <td>{\"price\": 22.5, \"category\": \"Novela Hist\\u00f3...</td>\n",
       "      <td>{'price': 22.5, 'category': 'Novela Histórica'}</td>\n",
       "      <td>22.50</td>\n",
       "      <td>Novela Histórica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Guía de Inversión Inteligente</td>\n",
       "      <td>{\"price\": 35.0, \"category\": \"Econom\\u00eda y F...</td>\n",
       "      <td>{'price': 35.0, 'category': 'Economía y Finanz...</td>\n",
       "      <td>35.00</td>\n",
       "      <td>Economía y Finanzas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Recetas de la Abuela</td>\n",
       "      <td>{\"price\": 18.75, \"category\": \"Cocina\"}</td>\n",
       "      <td>{'price': 18.75, 'category': 'Cocina'}</td>\n",
       "      <td>18.75</td>\n",
       "      <td>Cocina</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Atlas Mundial Actualizado</td>\n",
       "      <td>{\"price\": 49.99, \"category\": \"Geograf\\u00eda\"}</td>\n",
       "      <td>{'price': 49.99, 'category': 'Geografía'}</td>\n",
       "      <td>49.99</td>\n",
       "      <td>Geografía</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   item_id                           name  \\\n",
       "0        1          Crónicas de la Sombra   \n",
       "1        2           El Jardín Silencioso   \n",
       "2        3  Guía de Inversión Inteligente   \n",
       "3        4           Recetas de la Abuela   \n",
       "4        5      Atlas Mundial Actualizado   \n",
       "\n",
       "                                          attributes  \\\n",
       "0  {\"price\": 15.99, \"category\": \"Ficci\\u00f3n Fan...   \n",
       "1  {\"price\": 22.5, \"category\": \"Novela Hist\\u00f3...   \n",
       "2  {\"price\": 35.0, \"category\": \"Econom\\u00eda y F...   \n",
       "3             {\"price\": 18.75, \"category\": \"Cocina\"}   \n",
       "4     {\"price\": 49.99, \"category\": \"Geograf\\u00eda\"}   \n",
       "\n",
       "                                     attributes_dict  price  \\\n",
       "0  {'price': 15.99, 'category': 'Ficción Fantásti...  15.99   \n",
       "1    {'price': 22.5, 'category': 'Novela Histórica'}  22.50   \n",
       "2  {'price': 35.0, 'category': 'Economía y Finanz...  35.00   \n",
       "3             {'price': 18.75, 'category': 'Cocina'}  18.75   \n",
       "4          {'price': 49.99, 'category': 'Geografía'}  49.99   \n",
       "\n",
       "              category  \n",
       "0   Ficción Fantástica  \n",
       "1     Novela Histórica  \n",
       "2  Economía y Finanzas  \n",
       "3               Cocina  \n",
       "4            Geografía  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Deserialización de los atributos del item\n",
    "if 'attributes' in items_df.columns:\n",
    "    # 1. Deserializar el JSON y convertirlo en una Serie de diccionarios\n",
    "    items_df['attributes_dict'] = items_df['attributes'].apply(\n",
    "        lambda x: json.loads(x) if pd.notna(x) and isinstance(x, str) else {}\n",
    "    )\n",
    "    # Expenimos los diccionarios en columnas separadas\n",
    "    temp_attr_df = items_df['attributes_dict'].apply(pd.Series)\n",
    "    # Concatenamos las columnas expandidas al DataFrame principal y renombrar para evitar colisión\n",
    "    # El DataFrame ITEMS_DF final tendrá 'item_id', 'name', 'attributes' (el JSON original), y las columnas expandidas.\n",
    "    # Ahora el DF contiene todos los atributos como columnas separadas.\n",
    "    items_df = pd.concat([items_df, temp_attr_df], axis=1)\n",
    "if 'id' in users_df.columns: #nos aseguramos que el id sea int\n",
    "    users_df['id'] = users_df['id'].astype(int)\n",
    "items_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.Modelado\n",
    "## Selección de técnica de modelado\n",
    "Dado que en el planteamiento del problema se nos especifica que la cantidad de ítems es fija, el numero de usuarios aumenta y registramos las preferencias del usuario, se seleccionó construir un sistema recomendador de filtro colaborativo, basado en usuarios.\n",
    "Utilizaremos la similitud entre usuarios en función de sus preferencias para realizar recomendaciones. Recordemos que como hipótesis tenemos que usuarios similares tienden a gustarle items similares.\n",
    "Los pasos a seguir son los siguientes:\n",
    "\n",
    "1. Encontrar usuarios similares en función de los ratings que han dado a los productos de la base de datos.\n",
    "2. Identificar los items que usuarios similares han ranqueado alto, y los usuarios no han consumido\n",
    "3. Recomendar items en función de este ranking.\n",
    "\n",
    "## Construcción del modelo\n",
    "### Matriz de preferencias\n",
    "Vamos a crear un amatriz Usuario x Item con el puntaje dado por cada usuario a cada item que compro. Es una matriz dispersa por la que habrá muchos valores nulos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>name</th>\n",
       "      <th>Agujeros Negros</th>\n",
       "      <th>Algoritmos Avanzados en Java</th>\n",
       "      <th>Aromaterapia</th>\n",
       "      <th>Asesinato en el Tren Nocturno</th>\n",
       "      <th>Atlas Mundial Actualizado</th>\n",
       "      <th>Bases de Datos SQL</th>\n",
       "      <th>Biografía de Marie Curie</th>\n",
       "      <th>Bolsa de Valores Avanzada</th>\n",
       "      <th>Caligrafía Japonesa</th>\n",
       "      <th>Cartas de Amor Perdidas</th>\n",
       "      <th>...</th>\n",
       "      <th>Sin Rastro</th>\n",
       "      <th>Sonetos al Mar</th>\n",
       "      <th>Sueños de Androides</th>\n",
       "      <th>Tapas Españolas</th>\n",
       "      <th>Testigo Ocular</th>\n",
       "      <th>Versos Olvidados</th>\n",
       "      <th>Voces de la Guerra Civil</th>\n",
       "      <th>Yoga Aéreo</th>\n",
       "      <th>Yoga para Principiantes</th>\n",
       "      <th>Época Medieval</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 100 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "name     Agujeros Negros  Algoritmos Avanzados en Java  Aromaterapia  \\\n",
       "user_id                                                                \n",
       "1                    NaN                           NaN           NaN   \n",
       "2                    NaN                           NaN           NaN   \n",
       "3                    NaN                           NaN           NaN   \n",
       "4                    NaN                           5.0           3.0   \n",
       "5                    NaN                           NaN           NaN   \n",
       "\n",
       "name     Asesinato en el Tren Nocturno  Atlas Mundial Actualizado  \\\n",
       "user_id                                                             \n",
       "1                                  NaN                        NaN   \n",
       "2                                  4.0                        NaN   \n",
       "3                                  NaN                        3.0   \n",
       "4                                  NaN                        NaN   \n",
       "5                                  NaN                        NaN   \n",
       "\n",
       "name     Bases de Datos SQL  Biografía de Marie Curie  \\\n",
       "user_id                                                 \n",
       "1                       NaN                       2.0   \n",
       "2                       NaN                       NaN   \n",
       "3                       NaN                       NaN   \n",
       "4                       NaN                       NaN   \n",
       "5                       NaN                       NaN   \n",
       "\n",
       "name     Bolsa de Valores Avanzada  Caligrafía Japonesa  \\\n",
       "user_id                                                   \n",
       "1                              NaN                  NaN   \n",
       "2                              NaN                  NaN   \n",
       "3                              NaN                  2.0   \n",
       "4                              NaN                  NaN   \n",
       "5                              NaN                  NaN   \n",
       "\n",
       "name     Cartas de Amor Perdidas  ...  Sin Rastro  Sonetos al Mar  \\\n",
       "user_id                           ...                               \n",
       "1                            NaN  ...         4.0             NaN   \n",
       "2                            NaN  ...         NaN             NaN   \n",
       "3                            NaN  ...         NaN             NaN   \n",
       "4                            NaN  ...         NaN             NaN   \n",
       "5                            NaN  ...         NaN             NaN   \n",
       "\n",
       "name     Sueños de Androides  Tapas Españolas  Testigo Ocular  \\\n",
       "user_id                                                         \n",
       "1                        NaN              NaN             NaN   \n",
       "2                        3.0              NaN             NaN   \n",
       "3                        NaN              NaN             NaN   \n",
       "4                        NaN              NaN             2.0   \n",
       "5                        NaN              NaN             NaN   \n",
       "\n",
       "name     Versos Olvidados  Voces de la Guerra Civil  Yoga Aéreo  \\\n",
       "user_id                                                           \n",
       "1                     NaN                       NaN         NaN   \n",
       "2                     5.0                       NaN         NaN   \n",
       "3                     NaN                       NaN         NaN   \n",
       "4                     NaN                       NaN         4.0   \n",
       "5                     NaN                       NaN         NaN   \n",
       "\n",
       "name     Yoga para Principiantes  Época Medieval  \n",
       "user_id                                           \n",
       "1                            NaN             NaN  \n",
       "2                            5.0             NaN  \n",
       "3                            NaN             NaN  \n",
       "4                            NaN             NaN  \n",
       "5                            NaN             1.0  \n",
       "\n",
       "[5 rows x 100 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix = df.pivot_table(index='user_id', columns='name', values='preference_value')# Creamos la matriz usuario-item\n",
    "matrix.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hay personas que tienden a dar un puntaje mayor que otras, por lo que normalizaremos los valores. \n",
    "Hacemos que todos los puntajes tengan la misma media (0) y la misma desviación estandar (1)\n",
    "Luego de la normalización, los valores negativos corresponden a las puntuaciones que un usuario da por debajo de su promedio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>name</th>\n",
       "      <th>Agujeros Negros</th>\n",
       "      <th>Algoritmos Avanzados en Java</th>\n",
       "      <th>Aromaterapia</th>\n",
       "      <th>Asesinato en el Tren Nocturno</th>\n",
       "      <th>Atlas Mundial Actualizado</th>\n",
       "      <th>Bases de Datos SQL</th>\n",
       "      <th>Biografía de Marie Curie</th>\n",
       "      <th>Bolsa de Valores Avanzada</th>\n",
       "      <th>Caligrafía Japonesa</th>\n",
       "      <th>Cartas de Amor Perdidas</th>\n",
       "      <th>...</th>\n",
       "      <th>Sin Rastro</th>\n",
       "      <th>Sonetos al Mar</th>\n",
       "      <th>Sueños de Androides</th>\n",
       "      <th>Tapas Españolas</th>\n",
       "      <th>Testigo Ocular</th>\n",
       "      <th>Versos Olvidados</th>\n",
       "      <th>Voces de la Guerra Civil</th>\n",
       "      <th>Yoga Aéreo</th>\n",
       "      <th>Yoga para Principiantes</th>\n",
       "      <th>Época Medieval</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.106797</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.474342</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.380319</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.253546</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.014185</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.014185</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.283193</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.227168</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1.587011</td>\n",
       "      <td>-0.083527</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.918796</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.751742</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.490788</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 100 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "name     Agujeros Negros  Algoritmos Avanzados en Java  Aromaterapia  \\\n",
       "user_id                                                                \n",
       "1                    NaN                           NaN           NaN   \n",
       "2                    NaN                           NaN           NaN   \n",
       "3                    NaN                           NaN           NaN   \n",
       "4                    NaN                      1.587011     -0.083527   \n",
       "5                    NaN                           NaN           NaN   \n",
       "\n",
       "name     Asesinato en el Tren Nocturno  Atlas Mundial Actualizado  \\\n",
       "user_id                                                             \n",
       "1                                  NaN                        NaN   \n",
       "2                             0.380319                        NaN   \n",
       "3                                  NaN                  -0.283193   \n",
       "4                                  NaN                        NaN   \n",
       "5                                  NaN                        NaN   \n",
       "\n",
       "name     Bases de Datos SQL  Biografía de Marie Curie  \\\n",
       "user_id                                                 \n",
       "1                       NaN                 -1.106797   \n",
       "2                       NaN                       NaN   \n",
       "3                       NaN                       NaN   \n",
       "4                       NaN                       NaN   \n",
       "5                       NaN                       NaN   \n",
       "\n",
       "name     Bolsa de Valores Avanzada  Caligrafía Japonesa  \\\n",
       "user_id                                                   \n",
       "1                              NaN                  NaN   \n",
       "2                              NaN                  NaN   \n",
       "3                              NaN            -1.227168   \n",
       "4                              NaN                  NaN   \n",
       "5                              NaN                  NaN   \n",
       "\n",
       "name     Cartas de Amor Perdidas  ...  Sin Rastro  Sonetos al Mar  \\\n",
       "user_id                           ...                               \n",
       "1                            NaN  ...    0.474342             NaN   \n",
       "2                            NaN  ...         NaN             NaN   \n",
       "3                            NaN  ...         NaN             NaN   \n",
       "4                            NaN  ...         NaN             NaN   \n",
       "5                            NaN  ...         NaN             NaN   \n",
       "\n",
       "name     Sueños de Androides  Tapas Españolas  Testigo Ocular  \\\n",
       "user_id                                                         \n",
       "1                        NaN              NaN             NaN   \n",
       "2                  -0.253546              NaN             NaN   \n",
       "3                        NaN              NaN             NaN   \n",
       "4                        NaN              NaN       -0.918796   \n",
       "5                        NaN              NaN             NaN   \n",
       "\n",
       "name     Versos Olvidados  Voces de la Guerra Civil  Yoga Aéreo  \\\n",
       "user_id                                                           \n",
       "1                     NaN                       NaN         NaN   \n",
       "2                1.014185                       NaN         NaN   \n",
       "3                     NaN                       NaN         NaN   \n",
       "4                     NaN                       NaN    0.751742   \n",
       "5                     NaN                       NaN         NaN   \n",
       "\n",
       "name     Yoga para Principiantes  Época Medieval  \n",
       "user_id                                           \n",
       "1                            NaN             NaN  \n",
       "2                       1.014185             NaN  \n",
       "3                            NaN             NaN  \n",
       "4                            NaN             NaN  \n",
       "5                            NaN       -1.490788  \n",
       "\n",
       "[5 rows x 100 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "user_item_matrix = matrix.copy()# hacemos una copia para trabajar sin alterar la original\n",
    "row_mean = user_item_matrix.mean(axis=1)# Calculamos el promedio por fila\n",
    "row_std = user_item_matrix.std(axis=1)# Calculamos la desviación estándar por fila\n",
    "row_std[row_std == 0] = 1 # Evitamos división por cero\n",
    "matrix_norm = user_item_matrix.sub(row_mean, axis=0).div(row_std, axis=0)# Normalizamos la matriz usuario-item\n",
    "matrix_norm.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Similitud entre usuarios\n",
    "Usaremos la similitud de coseno para determinar la similitud entre usuarios.\n",
    "Esto mide el \"ángulo\" entre los vectores de preferencias de dos usuarios en el espacio de ítems. Un valor cercano a 1 indica alta similitud."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rellenamos los valores NaN con 0 para calcular similitudes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>name</th>\n",
       "      <th>Agujeros Negros</th>\n",
       "      <th>Algoritmos Avanzados en Java</th>\n",
       "      <th>Aromaterapia</th>\n",
       "      <th>Asesinato en el Tren Nocturno</th>\n",
       "      <th>Atlas Mundial Actualizado</th>\n",
       "      <th>Bases de Datos SQL</th>\n",
       "      <th>Biografía de Marie Curie</th>\n",
       "      <th>Bolsa de Valores Avanzada</th>\n",
       "      <th>Caligrafía Japonesa</th>\n",
       "      <th>Cartas de Amor Perdidas</th>\n",
       "      <th>...</th>\n",
       "      <th>Sin Rastro</th>\n",
       "      <th>Sonetos al Mar</th>\n",
       "      <th>Sueños de Androides</th>\n",
       "      <th>Tapas Españolas</th>\n",
       "      <th>Testigo Ocular</th>\n",
       "      <th>Versos Olvidados</th>\n",
       "      <th>Voces de la Guerra Civil</th>\n",
       "      <th>Yoga Aéreo</th>\n",
       "      <th>Yoga para Principiantes</th>\n",
       "      <th>Época Medieval</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.106797</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.474342</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.380319</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.253546</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.014185</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.014185</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.283193</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.227168</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.587011</td>\n",
       "      <td>-0.083527</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.918796</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.751742</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.490788</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 100 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "name     Agujeros Negros  Algoritmos Avanzados en Java  Aromaterapia  \\\n",
       "user_id                                                                \n",
       "1                    0.0                      0.000000      0.000000   \n",
       "2                    0.0                      0.000000      0.000000   \n",
       "3                    0.0                      0.000000      0.000000   \n",
       "4                    0.0                      1.587011     -0.083527   \n",
       "5                    0.0                      0.000000      0.000000   \n",
       "\n",
       "name     Asesinato en el Tren Nocturno  Atlas Mundial Actualizado  \\\n",
       "user_id                                                             \n",
       "1                             0.000000                   0.000000   \n",
       "2                             0.380319                   0.000000   \n",
       "3                             0.000000                  -0.283193   \n",
       "4                             0.000000                   0.000000   \n",
       "5                             0.000000                   0.000000   \n",
       "\n",
       "name     Bases de Datos SQL  Biografía de Marie Curie  \\\n",
       "user_id                                                 \n",
       "1                       0.0                 -1.106797   \n",
       "2                       0.0                  0.000000   \n",
       "3                       0.0                  0.000000   \n",
       "4                       0.0                  0.000000   \n",
       "5                       0.0                  0.000000   \n",
       "\n",
       "name     Bolsa de Valores Avanzada  Caligrafía Japonesa  \\\n",
       "user_id                                                   \n",
       "1                              0.0             0.000000   \n",
       "2                              0.0             0.000000   \n",
       "3                              0.0            -1.227168   \n",
       "4                              0.0             0.000000   \n",
       "5                              0.0             0.000000   \n",
       "\n",
       "name     Cartas de Amor Perdidas  ...  Sin Rastro  Sonetos al Mar  \\\n",
       "user_id                           ...                               \n",
       "1                            0.0  ...    0.474342             0.0   \n",
       "2                            0.0  ...    0.000000             0.0   \n",
       "3                            0.0  ...    0.000000             0.0   \n",
       "4                            0.0  ...    0.000000             0.0   \n",
       "5                            0.0  ...    0.000000             0.0   \n",
       "\n",
       "name     Sueños de Androides  Tapas Españolas  Testigo Ocular  \\\n",
       "user_id                                                         \n",
       "1                   0.000000              0.0        0.000000   \n",
       "2                  -0.253546              0.0        0.000000   \n",
       "3                   0.000000              0.0        0.000000   \n",
       "4                   0.000000              0.0       -0.918796   \n",
       "5                   0.000000              0.0        0.000000   \n",
       "\n",
       "name     Versos Olvidados  Voces de la Guerra Civil  Yoga Aéreo  \\\n",
       "user_id                                                           \n",
       "1                0.000000                       0.0    0.000000   \n",
       "2                1.014185                       0.0    0.000000   \n",
       "3                0.000000                       0.0    0.000000   \n",
       "4                0.000000                       0.0    0.751742   \n",
       "5                0.000000                       0.0    0.000000   \n",
       "\n",
       "name     Yoga para Principiantes  Época Medieval  \n",
       "user_id                                           \n",
       "1                       0.000000        0.000000  \n",
       "2                       1.014185        0.000000  \n",
       "3                       0.000000        0.000000  \n",
       "4                       0.000000        0.000000  \n",
       "5                       0.000000       -1.490788  \n",
       "\n",
       "[5 rows x 100 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_item_matrix_filled = matrix_norm.fillna(0)# Rellenamos los valores NaN con 0\n",
    "user_item_matrix_filled.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>name</th>\n",
       "      <th>Agujeros Negros</th>\n",
       "      <th>Algoritmos Avanzados en Java</th>\n",
       "      <th>Aromaterapia</th>\n",
       "      <th>Asesinato en el Tren Nocturno</th>\n",
       "      <th>Atlas Mundial Actualizado</th>\n",
       "      <th>Bases de Datos SQL</th>\n",
       "      <th>Biografía de Marie Curie</th>\n",
       "      <th>Bolsa de Valores Avanzada</th>\n",
       "      <th>Caligrafía Japonesa</th>\n",
       "      <th>Cartas de Amor Perdidas</th>\n",
       "      <th>...</th>\n",
       "      <th>Sin Rastro</th>\n",
       "      <th>Sonetos al Mar</th>\n",
       "      <th>Sueños de Androides</th>\n",
       "      <th>Tapas Españolas</th>\n",
       "      <th>Testigo Ocular</th>\n",
       "      <th>Versos Olvidados</th>\n",
       "      <th>Voces de la Guerra Civil</th>\n",
       "      <th>Yoga Aéreo</th>\n",
       "      <th>Yoga para Principiantes</th>\n",
       "      <th>Época Medieval</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.106797</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.474342</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.380319</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.253546</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.014185</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.014185</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.283193</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.227168</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.587011</td>\n",
       "      <td>-0.083527</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.918796</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.751742</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.490788</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 100 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "name     Agujeros Negros  Algoritmos Avanzados en Java  Aromaterapia  \\\n",
       "user_id                                                                \n",
       "1                    0.0                      0.000000      0.000000   \n",
       "2                    0.0                      0.000000      0.000000   \n",
       "3                    0.0                      0.000000      0.000000   \n",
       "4                    0.0                      1.587011     -0.083527   \n",
       "5                    0.0                      0.000000      0.000000   \n",
       "\n",
       "name     Asesinato en el Tren Nocturno  Atlas Mundial Actualizado  \\\n",
       "user_id                                                             \n",
       "1                             0.000000                   0.000000   \n",
       "2                             0.380319                   0.000000   \n",
       "3                             0.000000                  -0.283193   \n",
       "4                             0.000000                   0.000000   \n",
       "5                             0.000000                   0.000000   \n",
       "\n",
       "name     Bases de Datos SQL  Biografía de Marie Curie  \\\n",
       "user_id                                                 \n",
       "1                       0.0                 -1.106797   \n",
       "2                       0.0                  0.000000   \n",
       "3                       0.0                  0.000000   \n",
       "4                       0.0                  0.000000   \n",
       "5                       0.0                  0.000000   \n",
       "\n",
       "name     Bolsa de Valores Avanzada  Caligrafía Japonesa  \\\n",
       "user_id                                                   \n",
       "1                              0.0             0.000000   \n",
       "2                              0.0             0.000000   \n",
       "3                              0.0            -1.227168   \n",
       "4                              0.0             0.000000   \n",
       "5                              0.0             0.000000   \n",
       "\n",
       "name     Cartas de Amor Perdidas  ...  Sin Rastro  Sonetos al Mar  \\\n",
       "user_id                           ...                               \n",
       "1                            0.0  ...    0.474342             0.0   \n",
       "2                            0.0  ...    0.000000             0.0   \n",
       "3                            0.0  ...    0.000000             0.0   \n",
       "4                            0.0  ...    0.000000             0.0   \n",
       "5                            0.0  ...    0.000000             0.0   \n",
       "\n",
       "name     Sueños de Androides  Tapas Españolas  Testigo Ocular  \\\n",
       "user_id                                                         \n",
       "1                   0.000000              0.0        0.000000   \n",
       "2                  -0.253546              0.0        0.000000   \n",
       "3                   0.000000              0.0        0.000000   \n",
       "4                   0.000000              0.0       -0.918796   \n",
       "5                   0.000000              0.0        0.000000   \n",
       "\n",
       "name     Versos Olvidados  Voces de la Guerra Civil  Yoga Aéreo  \\\n",
       "user_id                                                           \n",
       "1                0.000000                       0.0    0.000000   \n",
       "2                1.014185                       0.0    0.000000   \n",
       "3                0.000000                       0.0    0.000000   \n",
       "4                0.000000                       0.0    0.751742   \n",
       "5                0.000000                       0.0    0.000000   \n",
       "\n",
       "name     Yoga para Principiantes  Época Medieval  \n",
       "user_id                                           \n",
       "1                       0.000000        0.000000  \n",
       "2                       1.014185        0.000000  \n",
       "3                       0.000000        0.000000  \n",
       "4                       0.000000        0.000000  \n",
       "5                       0.000000       -1.490788  \n",
       "\n",
       "[5 rows x 100 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "user_similarity_cosine = cosine_similarity(user_item_matrix_filled)# Calculamos la similitud del coseno entre los usuarios\n",
    "user_item_matrix_filled.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los valores estan en el intervalo [-1, 1], donde valores positivos significan mayor similitud."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matriz de similitud entre usuarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>...</th>\n",
       "      <th>691</th>\n",
       "      <th>692</th>\n",
       "      <th>693</th>\n",
       "      <th>694</th>\n",
       "      <th>695</th>\n",
       "      <th>696</th>\n",
       "      <th>697</th>\n",
       "      <th>698</th>\n",
       "      <th>699</th>\n",
       "      <th>700</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.026530</td>\n",
       "      <td>-0.017687</td>\n",
       "      <td>-0.160947</td>\n",
       "      <td>-0.045985</td>\n",
       "      <td>0.183940</td>\n",
       "      <td>0.201626</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.074283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.029778</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.034034</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.134717</td>\n",
       "      <td>0.008508</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.124791</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.106356</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.260813</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.140438</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.015839</td>\n",
       "      <td>-0.041181</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.133046</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.014715</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.012146</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.311131</td>\n",
       "      <td>-0.227976</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.293379</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.286501</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.039416</td>\n",
       "      <td>0.030320</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.018192</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.150083</td>\n",
       "      <td>-0.259234</td>\n",
       "      <td>0.016676</td>\n",
       "      <td>0.183434</td>\n",
       "      <td>0.030320</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 700 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     1    2    3    4    5    6    7    8    9        10  ...       691  \\\n",
       "1  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.000000  ...  0.026530   \n",
       "2  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.029778  ... -0.034034   \n",
       "3  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.000000  ...  0.260813   \n",
       "4  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0 -0.014715  ...  0.000000   \n",
       "5  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.286501  ... -0.039416   \n",
       "\n",
       "        692       693       694       695       696       697       698  \\\n",
       "1 -0.017687 -0.160947 -0.045985  0.183940  0.201626  0.000000  0.000000   \n",
       "2  0.000000  0.134717  0.008508  0.000000  0.000000 -0.124791  0.000000   \n",
       "3  0.000000 -0.140438  0.000000 -0.015839 -0.041181  0.000000  0.000000   \n",
       "4 -0.012146  0.000000 -0.311131 -0.227976  0.000000  0.000000 -0.293379   \n",
       "5  0.030320  0.000000 -0.018192  0.000000 -0.150083 -0.259234  0.016676   \n",
       "\n",
       "        699       700  \n",
       "1  0.000000 -0.074283  \n",
       "2  0.106356  0.000000  \n",
       "3  0.133046  0.000000  \n",
       "4  0.000000  0.000000  \n",
       "5  0.183434  0.030320  \n",
       "\n",
       "[5 rows x 700 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_ids = user_item_matrix_filled.index.tolist()# Obtenemos los IDs de usuario\n",
    "user_similarity = pd.DataFrame( #Creamos la matriz de similitud de usuarios\n",
    "    user_similarity_cosine, \n",
    "    index=user_ids, \n",
    "    columns=user_ids\n",
    ")\n",
    "user_similarity.index = user_similarity.index.astype(str)# Aseguramos que los índices sean strings\n",
    "user_similarity.columns = user_similarity.columns.astype(str)# Aseguramos que las columnas sean strings\n",
    "user_similarity.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dado un usuario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "user = \"350\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Veamos los items comprados por el mismo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Desarrollo Web con React',\n",
       " 'El Legado de Einstein',\n",
       " 'Fotografía Digital',\n",
       " 'Geología Terrestre',\n",
       " 'Masajes Terapéuticos',\n",
       " 'Mitología Griega',\n",
       " 'Robots en el Tiempo']"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_items = matrix_norm.loc[int(user)]# Obtenemos las preferencias del usuario\n",
    "items_comprados = user_items[user_items.notna()].index.tolist()# Items comprados por el usuario\n",
    "items_comprados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obtenemos los 30 usuarios mas similares a "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "322    1.000000\n",
       "378    1.000000\n",
       "308    1.000000\n",
       "336    1.000000\n",
       "364    1.000000\n",
       "392    1.000000\n",
       "449    0.312799\n",
       "421    0.312799\n",
       "237    0.312799\n",
       "209    0.312799\n",
       "265    0.312799\n",
       "293    0.312799\n",
       "539    0.208418\n",
       "519    0.208418\n",
       "499    0.208418\n",
       "549    0.208418\n",
       "479    0.208418\n",
       "469    0.208418\n",
       "459    0.208418\n",
       "529    0.208418\n",
       "489    0.208418\n",
       "509    0.208418\n",
       "180    0.198507\n",
       "442    0.148810\n",
       "230    0.148810\n",
       "202    0.148810\n",
       "414    0.148810\n",
       "258    0.148810\n",
       "286    0.148810\n",
       "647    0.108740\n",
       "Name: 350, dtype: float64"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n=30\n",
    "        \n",
    "similar_users = ( # Obtenemos usuarios similares\n",
    "        user_similarity[user]\n",
    "        .sort_values(ascending=False)\n",
    "        .drop(user, errors='ignore')\n",
    "        .head(n)\n",
    "    )\n",
    "similar_users"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Veamos que items compraron usuarios similares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Usuarios similares a 350: [322, 378, 308, 336, 364, 392, 449, 421, 237, 209, 265, 293, 539, 519, 499, 549, 479, 469, 459, 529, 489, 509, 180, 442, 230, 202, 414, 258, 286, 647]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Asesinato en el Tren Nocturno',\n",
       " 'Ciberseguridad Esencial',\n",
       " 'Civilizaciones Antiguas',\n",
       " 'Cloud Computing AWS',\n",
       " 'Criptomonedas y Blockchain',\n",
       " 'Crónicas de la Sombra',\n",
       " 'Desarrollo Web con React',\n",
       " 'Desarrollo de Videojuegos Unity',\n",
       " 'El Legado de Einstein',\n",
       " 'El Silencio del Testigo',\n",
       " 'Escultura Moderna',\n",
       " 'Finanzas Personales 2026',\n",
       " 'Fotografía Digital',\n",
       " 'Geología Terrestre',\n",
       " 'Historia del Arte Renacentista',\n",
       " 'La Balada del Viajero',\n",
       " 'La Conquista del Espacio',\n",
       " 'La Profecía del Sol',\n",
       " 'La Revolución Industrial',\n",
       " 'La Vida en Marte',\n",
       " 'Masajes Terapéuticos',\n",
       " 'Microeconomía Aplicada',\n",
       " 'Mitología Griega',\n",
       " 'Panadería Artesanal',\n",
       " 'Pilates en Casa',\n",
       " 'Recetas de la Abuela',\n",
       " 'Repostería Francesa',\n",
       " 'Robots en el Tiempo',\n",
       " 'Sonetos al Mar',\n",
       " 'Yoga Aéreo',\n",
       " 'Época Medieval']"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# items comprados por usuarios similares\n",
    "#  Obtenemos la lista de IDs de usuarios similares asegurandonos que sean enteros\n",
    "similar_users_ids = similar_users.index.astype(int).tolist()\n",
    "print(f\"Usuarios similares a {user}: {similar_users_ids}\")\n",
    "\n",
    "## Filtrar matrix_norm para obtener solo las filas de los usuarios similares\n",
    "# Usamos .loc[] para indexar por las etiquetas del índice (los user_id).\n",
    "similar_user_items = matrix_norm.loc[similar_users_ids]\n",
    "# Identificar los ítems que *al menos un* usuario similar ha comprado/calificado\n",
    "items_comprados_usuarios_similares = similar_user_items.columns[\n",
    "    similar_user_items.notna().any()\n",
    "].tolist()\n",
    "\n",
    "items_comprados_usuarios_similares"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Items candidatos para recomendar (Son los items comprados por usuarios similares excluyendo los que el usuario ya compro)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['La Vida en Marte',\n",
       " 'Yoga Aéreo',\n",
       " 'La Balada del Viajero',\n",
       " 'Recetas de la Abuela',\n",
       " 'Microeconomía Aplicada',\n",
       " 'La Conquista del Espacio',\n",
       " 'Repostería Francesa',\n",
       " 'El Silencio del Testigo',\n",
       " 'Desarrollo de Videojuegos Unity',\n",
       " 'Sonetos al Mar',\n",
       " 'La Profecía del Sol',\n",
       " 'Crónicas de la Sombra',\n",
       " 'Ciberseguridad Esencial',\n",
       " 'La Revolución Industrial',\n",
       " 'Civilizaciones Antiguas',\n",
       " 'Escultura Moderna',\n",
       " 'Finanzas Personales 2026',\n",
       " 'Cloud Computing AWS',\n",
       " 'Asesinato en el Tren Nocturno',\n",
       " 'Época Medieval',\n",
       " 'Panadería Artesanal',\n",
       " 'Historia del Arte Renacentista',\n",
       " 'Criptomonedas y Blockchain',\n",
       " 'Pilates en Casa']"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "candidate_items = list(set(items_comprados_usuarios_similares) - set(items_comprados))\n",
    "candidate_items"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a ponderar los items de forma tal que la puntuación sea igual al promedio ponderado entre la similitud del usuario y el rating que le dió ese usuario.\n",
    "Los usuarios más similares van a pesar más en el rating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "name\n",
       "La Vida en Marte                  -0.027174\n",
       "Yoga Aéreo                         0.030236\n",
       "La Balada del Viajero             -0.003397\n",
       "Recetas de la Abuela               0.083149\n",
       "Microeconomía Aplicada            -0.015285\n",
       "La Conquista del Espacio           0.083149\n",
       "Repostería Francesa               -0.315010\n",
       "El Silencio del Testigo            0.020380\n",
       "Desarrollo de Videojuegos Unity   -0.128504\n",
       "Sonetos al Mar                    -0.052334\n",
       "La Profecía del Sol                0.094143\n",
       "Crónicas de la Sombra              0.030236\n",
       "Ciberseguridad Esencial            0.259150\n",
       "La Revolución Industrial          -0.032115\n",
       "Civilizaciones Antiguas           -0.032115\n",
       "Escultura Moderna                  0.004325\n",
       "Finanzas Personales 2026          -0.022677\n",
       "Cloud Computing AWS                0.219858\n",
       "Asesinato en el Tren Nocturno     -0.003397\n",
       "Época Medieval                     0.192688\n",
       "Panadería Artesanal               -0.256917\n",
       "Historia del Arte Renacentista     0.008492\n",
       "Criptomonedas y Blockchain         0.215533\n",
       "Pilates en Casa                    0.011245\n",
       "dtype: float64"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similar_user_preferences = matrix_norm.loc[similar_users_ids]# Preferencias de usuarios similares\n",
    "items_comprados_por_similares = similar_user_preferences.columns[similar_user_preferences.notna().any()].tolist()# Items comprados por usuarios similares\n",
    "candidate_items = list(set(items_comprados_por_similares) - set(items_comprados))# Items candidatos para recomendar\n",
    "candidate_matrix= similar_user_preferences[candidate_items].fillna(0).copy()# Rellenamos NaN con 0\n",
    "similar_users.index = similar_users.index.astype(candidate_matrix.index.dtype)# Aseguramos que los índices coincidan\n",
    "weighted_scores = candidate_matrix.multiply(similar_users, axis=0)# Puntuaciones ponderadas\n",
    "sum_similarity = similar_users.sum()# Suma de similitudes\n",
    "recommendation_scores = weighted_scores.sum(axis=0) / sum_similarity# Puntuaciones finales\n",
    "recommendation_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ordenamos las recomendaciones de forma descendente segun su puntuacion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recomendaciones_ordenadas = recommendation_scores.sort_values(ascending=False)# Ordenamos las recomendaciones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Recomendaciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Items recomendados para el usuario 350: \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Ciberseguridad Esencial',\n",
       " 'Cloud Computing AWS',\n",
       " 'Criptomonedas y Blockchain',\n",
       " 'Época Medieval',\n",
       " 'La Profecía del Sol',\n",
       " 'Recetas de la Abuela',\n",
       " 'La Conquista del Espacio',\n",
       " 'Yoga Aéreo',\n",
       " 'Crónicas de la Sombra',\n",
       " 'El Silencio del Testigo',\n",
       " 'Pilates en Casa',\n",
       " 'Historia del Arte Renacentista',\n",
       " 'Escultura Moderna',\n",
       " 'Asesinato en el Tren Nocturno',\n",
       " 'La Balada del Viajero',\n",
       " 'Microeconomía Aplicada',\n",
       " 'Finanzas Personales 2026',\n",
       " 'La Vida en Marte',\n",
       " 'Civilizaciones Antiguas',\n",
       " 'La Revolución Industrial',\n",
       " 'Sonetos al Mar',\n",
       " 'Desarrollo de Videojuegos Unity',\n",
       " 'Panadería Artesanal',\n",
       " 'Repostería Francesa']"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recomendaciones_finales = recomendaciones_ordenadas.index.tolist()# Lista final de recomendaciones\n",
    "print(f\"Items recomendados para el usuario {user}: \")\n",
    "recomendaciones_finales"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correccion del cold start\n",
    "El problema del Cold Start se presenta cuando un usuario es nuevo en la plataforma y, por lo tanto, no ha interactuado con ningún ítem. Sin historial de preferencias, el algoritmo de Filtro Colaborativo Basado en Usuarios no puede calcular la similitud con otros usuarios, lo que resulta en la imposibilidad de generar recomendaciones.\n",
    "Como solucion el sistema aplica una estrategia de recomendación basada en popularidad.\n",
    "La popularidad de un ítem se mide por el número de veces que ha sido calificado en el historial de preferencias.\n",
    "Se agrupan las preferencias po ítem y se cuenta el número total de registros para cada uno.\n",
    "Esta estrategia es eficaz porque asegura que el usuario nuevo sea expuesto a los artículos que han tenido mayor éxito entre la base de usuarios existente, maximizando la probabilidad de una interacción inicial positiva. Una vez que el usuario nuevo realiza una primera calificación, su ID ingresa a la matriz de preferencias y el sistema pasa a usar el modelo principal en futuras solicitudes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Top 10 items mas comprados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Fitness Funcional',\n",
       " 'Mitología Griega',\n",
       " 'El Último Dragón',\n",
       " 'Crimen en la Mansión',\n",
       " 'Biografía de Marie Curie',\n",
       " 'Historia del Arte Renacentista',\n",
       " 'El Misterio de la Calle Nueve',\n",
       " 'La Ciudad bajo la Niebla',\n",
       " 'Haikus Japoneses',\n",
       " 'Ciberseguridad Esencial']"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n=10\n",
    "top_items = df.groupby('name')['preference_value'].count().sort_values(ascending=False)# Contamos la cantidad de preferencias por item y los ordenamos\n",
    "top_items.head(n).index.tolist()# Retornamos los nombres de los items más populares"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Activacion del Cold Start\n",
    "Se activa en dos escenarios dentro de la función de recomendación principal\n",
    "1. Usuario sin preferencias: para esto definimos la siguiente funcion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El usuario 350 tiene preferencias registradas.\n",
      "El usuario 9999 no tiene preferencias registradas.\n"
     ]
    }
   ],
   "source": [
    "def user_has_preferences(user_id: int) -> bool:\n",
    "    \"\"\"Verifica si un usuario tiene preferencias registradas en la matriz normalizada.\n",
    "    Args:\n",
    "        user_id (int): ID del usuario a verificar.\n",
    "    Returns:\n",
    "        bool: True si el usuario tiene preferencias, False en caso contrario.\"\"\"\n",
    "    return user_id in matrix_norm.index\n",
    "# Ejemplo de uso\n",
    "user_id = 350 #ya sabemos que este usuario tiene preferencias\n",
    "if user_has_preferences(user_id):\n",
    "    print(f\"El usuario {user_id} tiene preferencias registradas.\")\n",
    "user_id = 9999 #suponemos que este usuario no existe\n",
    "if not user_has_preferences(user_id):\n",
    "    print(f\"El usuario {user_id} no tiene preferencias registradas.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Fallo del modelo principal: El modelo intenta la predicción, pero la suma de similitudes es cero."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluacion del modelo\n",
    "Primero encapsulamos el sistema en funciones para simplicidad\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['La Vida en Marte',\n",
       " 'Guía de Inversión Inteligente',\n",
       " 'Yoga Aéreo',\n",
       " 'La Balada del Viajero',\n",
       " 'Manual de Liderazgo Ágil',\n",
       " 'Recetas de la Abuela',\n",
       " 'Microeconomía Aplicada',\n",
       " 'La Conquista del Espacio',\n",
       " 'Repostería Francesa',\n",
       " 'Desarrollo de Videojuegos Unity']"
      ]
     },
     "execution_count": 278,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def initialize_db():\n",
    "    \"\"\"\n",
    "    Crea y puebla la base de datos SOLO si el archivo DB no existe.\n",
    "    Establece las claves primarias (compuestas) y foráneas.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Cargamos los datos desde los CSV\n",
    "        users_df = pd.read_csv(USERS_URL)\n",
    "        items_df = pd.read_csv(ITEMS_URL)\n",
    "        preferences_df = pd.read_csv(PREFERENCES_URL)\n",
    "        \n",
    "        # Preprocesamos los atributos de USERS\n",
    "        if 'id' not in users_df.columns: \n",
    "            id_cols = [col for col in users_df.columns if 'id' in col.lower()]\n",
    "            if id_cols:\n",
    "                users_df = users_df.rename(columns={id_cols[0]: 'id'})\n",
    "        \n",
    "        BASE_KEYS = ['id', 'username']\n",
    "        # Función para serializar atributos adicionales a JSON\n",
    "        def serialize_attributes(row):\n",
    "            attributes = {\n",
    "                k: v for k, v in row.items() \n",
    "                if k not in BASE_KEYS and pd.notna(v)\n",
    "            }\n",
    "            return json.dumps(attributes)# Serializamos a JSON\n",
    "        \n",
    "        \n",
    "        users_df['attributes'] = users_df.apply(serialize_attributes, axis=1)# Creamos la columna 'attributes' con JSON\n",
    "        users_df_clean = users_df[BASE_KEYS + ['attributes']].copy()# Filtramos solo las columnas necesarias        \n",
    "        \n",
    "        # Preprocesamiento de ITEMS \n",
    "        if 'id' in items_df.columns and 'item_id' not in items_df.columns:\n",
    "            items_df.rename(columns={'id': 'item_id'}, inplace=True)\n",
    "            \n",
    "        BASE_ITEM_KEYS = ['item_id', 'name']\n",
    "        def serialize_item_attributes(row):\n",
    "            attributes = {\n",
    "                k: v for k, v in row.items() \n",
    "                if k not in BASE_ITEM_KEYS and pd.notna(v)\n",
    "            }\n",
    "            return json.dumps(attributes)\n",
    "        \n",
    "        items_df['attributes'] = items_df.apply(serialize_item_attributes, axis=1)\n",
    "        items_df_clean = items_df[BASE_ITEM_KEYS + ['attributes']].copy()\n",
    "\n",
    "        # Mapeo y Filtrado de PREFERENCES \n",
    "        # Aseguramos que las columnas tengan los nombres correctos\n",
    "        preferences_df.rename(columns={\n",
    "            'user_id': 'user_id',\n",
    "            'item_id': 'item_id',\n",
    "            'preference_value': 'preference_value'\n",
    "        }, inplace=True)\n",
    "        \n",
    "        # Filtramos solo las columnas necesarias \n",
    "        preferences_df = preferences_df[['user_id', 'item_id', 'preference_value']].copy()\n",
    "        \n",
    "        # Aseguramos que ITEMS tenga 'item_id'\n",
    "        # Asumiendo que el CSV de Items usa 'item_id'\n",
    "        if 'id' in items_df.columns and 'item_id' not in items_df.columns:\n",
    "            items_df.rename(columns={'id': 'item_id'}, inplace=True)\n",
    "            \n",
    "        # ------------------------------------------------------------------------------------------------\n",
    "        # Creación de la base de datos SQLite y tablas con claves primarias y foráneas\n",
    "        # ------------------------------------------------------------------------------------------------\n",
    "        conn = sqlite3.connect(DB_NAME)# Conexión a la base de datos SQLite\n",
    "        cursor = conn.cursor()# Cursor para ejecutar comandos SQL\n",
    "        \n",
    "       #Creamos tabla de usuarios con id como PRIMARY KEY y username único\n",
    "        cursor.execute(\"\"\"\n",
    "             CREATE TABLE IF NOT EXISTS users (\n",
    "                id INTEGER PRIMARY KEY NOT NULL,\n",
    "                username TEXT UNIQUE NOT NULL,\n",
    "                attributes TEXT\n",
    "            );\n",
    "        \"\"\")\n",
    "        \n",
    "        # Creamos la tabla de items con item_id como PRIMARY KEY\n",
    "        cursor.execute(\"\"\"\n",
    "                CREATE TABLE IF NOT EXISTS items (\n",
    "                    item_id INTEGER PRIMARY KEY NOT NULL,\n",
    "                    name TEXT NOT NULL,\n",
    "                    attributes TEXT\n",
    "                );\n",
    "            \"\"\")\n",
    "        \n",
    "        #Creamos la tabla de preferencias con claves foráneas a las tablas users e items y clave primaria compuesta\n",
    "        cursor.execute(\"\"\"\n",
    "            CREATE TABLE IF NOT EXISTS preferences (\n",
    "                user_id INTEGER NOT NULL,\n",
    "                item_id INTEGER NOT NULL,\n",
    "                preference_value INTEGER NOT NULL,\n",
    "                PRIMARY KEY (user_id, item_id),\n",
    "                FOREIGN KEY(user_id) REFERENCES users(id) ON DELETE CASCADE,\n",
    "                FOREIGN KEY(item_id) REFERENCES items(item_id) ON DELETE CASCADE\n",
    "            );\n",
    "        \"\"\")\n",
    "        \n",
    "        #  Deshabilitamos la verificación de FK temporalmente (solo para carga inicial) para evitar errores de inserción\n",
    "        conn.execute(\"PRAGMA foreign_keys = OFF;\") \n",
    "\n",
    "        # Insertamos los datos en las tablas correspondientes\n",
    "        users_df_clean.to_sql('users', conn, if_exists='append', index=False)\n",
    "        items_df_clean.to_sql('items', conn, if_exists='append', index=False) \n",
    "        preferences_df.to_sql('preferences', conn, if_exists='append', index=False)\n",
    "        \n",
    "        # Volvemos a habilitar la verificación de claves foráneas\n",
    "        conn.execute(\"PRAGMA foreign_keys = ON;\")\n",
    "        \n",
    "        conn.commit()# Guardamos los cambios\n",
    "        conn.close()# Cerramos la conexión\n",
    "        \n",
    "        print(f\" Base de datos SQLite creada y cargada con éxito.\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\" Error al inicializar SQLite: {e}\")\n",
    "        raise\n",
    "\n",
    "def initial_load():\n",
    "    \"\"\"Carga los datos de SQLite (una vez que la DB existe y si no, la crea) y genera las matrices necesarias para el sistema recomendador.\n",
    "    Returns:\n",
    "        tuple: (df, matrix_norm, user_similarity, users_df, items_df)\"\"\"\n",
    "    if not(os.path.exists(DB_NAME)): # Verificamos si la base de datos ya existe\n",
    "        print(f\"Base de datos '{DB_NAME}' no encontrada. Creandola e inicializándola...\")\n",
    "        initialize_db() #Inicializa la DB si no existe\n",
    "    \n",
    "    # Consulta SQL para unir items y preferences\n",
    "    SQL_QUERY = \"\"\"\n",
    "SELECT \n",
    "    T1.item_id,\n",
    "    T1.name,\n",
    "    T2.user_id,\n",
    "    T2.preference_value\n",
    "FROM \n",
    "    items AS T1 \n",
    "INNER JOIN \n",
    "    preferences AS T2\n",
    "ON \n",
    "    T1.item_id = T2.item_id;\n",
    "\"\"\"\n",
    "    \n",
    "    conn = sqlite3.connect(DB_NAME)# Abrimos la conexión a la base de datos\n",
    "    df = pd.read_sql_query(SQL_QUERY, conn)# Leemos las preferencias uniendo items y preferences\n",
    "    users_df = pd.read_sql_query(\"SELECT id, username, attributes FROM users\", conn)# Leemos los usuarios desde la base de datos\n",
    "    items_df = pd.read_sql_query(\"SELECT * FROM items\", conn)# Leemos los items desde la base de datos\n",
    "    conn.close()# Cerramos la conexión a la base de datos\n",
    "\n",
    "    # Deserialización de los atributos del usuario\n",
    "    if 'attributes' in users_df.columns:\n",
    "        users_df['attributes'] = users_df['attributes'].apply(\n",
    "            lambda x: json.loads(x) if pd.notna(x) and isinstance(x, str) else {}\n",
    "        )\n",
    "    # Deserialización de los atributos del item\n",
    "    if 'attributes' in items_df.columns:\n",
    "        # 1. Deserializar el JSON y convertirlo en una Serie de diccionarios\n",
    "        items_df['attributes_dict'] = items_df['attributes'].apply(\n",
    "            lambda x: json.loads(x) if pd.notna(x) and isinstance(x, str) else {}\n",
    "        )\n",
    "        # Expenimos los diccionarios en columnas separadas\n",
    "        temp_attr_df = items_df['attributes_dict'].apply(pd.Series)\n",
    "        # Concatenamos las columnas expandidas al DataFrame principal y renombrar para evitar colisión\n",
    "        # El DataFrame ITEMS_DF final tendrá 'item_id', 'name', 'attributes' (el JSON original), y las columnas expandidas.\n",
    "        # Ahora el DF contiene todos los atributos como columnas separadas.\n",
    "        items_df = pd.concat([items_df, temp_attr_df], axis=1)\n",
    "    if 'id' in users_df.columns: #nos aseguramos que el id sea int\n",
    "        users_df['id'] = users_df['id'].astype(int)\n",
    "\n",
    "    #Creamos las matrices necesarias para el sistema recomendador\n",
    "    matrix = df.pivot_table(index='user_id', columns='name', values='preference_value')# Creamos la matriz usuario-item\n",
    "    user_item_matrix = matrix.copy()# hacemos una copia para trabajar sin alterar la original\n",
    "    row_mean = user_item_matrix.mean(axis=1)# Calculamos el promedio por fila\n",
    "    row_std = user_item_matrix.std(axis=1)# Calculamos la desviación estándar por fila\n",
    "    row_std[row_std == 0] = 1 # Evitamos división por cero\n",
    "    matrix_norm = user_item_matrix.sub(row_mean, axis=0).div(row_std, axis=0)# Normalizamos la matriz usuario-item\n",
    "    user_item_matrix_filled = matrix_norm.fillna(0)# Rellenamos los valores NaN con 0 para calcular similitudes\n",
    "    user_similarity_cosine = cosine_similarity(user_item_matrix_filled)# Calculamos la similitud del coseno entre los usuarios\n",
    "    user_ids = user_item_matrix_filled.index.tolist()# Obtenemos los IDs de usuario\n",
    "    user_similarity = pd.DataFrame( #Creamos la matriz de similitud de usuarios\n",
    "        user_similarity_cosine, \n",
    "        index=user_ids, \n",
    "        columns=user_ids\n",
    "    )\n",
    "    user_similarity.index = user_similarity.index.astype(str)# Aseguramos que los índices sean strings\n",
    "    user_similarity.columns = user_similarity.columns.astype(str)# Aseguramos que las columnas sean strings\n",
    "    # Retornamos los datos procesados\n",
    "    return df, matrix_norm, user_similarity, users_df, items_df,row_mean\n",
    "\n",
    "try:\n",
    "    DF, MATRIX_NORM, USER_SIMILARITY, USERS_DF, ITEMS_DF, row_mean = initial_load()#\n",
    "except Exception as e:# Manejo de errores en la carga inicial\n",
    "    print(f\" ERROR FATAL: La aplicación no pudo iniciar debido al error de carga/procesamiento: {e}\")\n",
    "def user_has_preferences(user_id: int) -> bool:\n",
    "    \"\"\"Verifica si un usuario tiene preferencias registradas en la matriz normalizada.\n",
    "    Args:a\n",
    "        user_id (int): ID del usuario a verificar.\n",
    "    Returns:\n",
    "        bool: True si el usuario tiene preferencias, False en caso contrario.\"\"\"\n",
    "    return user_id in MATRIX_NORM.index\n",
    "\n",
    "def cold_start_items_recommendations(number_max_of_recommendations: int) -> list: \n",
    "    \"\"\"Genera recomendaciones para usuarios nuevos basadas en los items más populares.\n",
    "    Args:\n",
    "        number_max_of_recommendations (int): Número máximo de items a recomendar.\n",
    "    Returns: \n",
    "        list: Lista de nombres de items recomendados.\"\"\"\n",
    "    top_items = DF.groupby('name')['preference_value'].count().sort_values(ascending=False)# Contamos la cantidad de preferencias por item y los ordenamos\n",
    "    return top_items.head(number_max_of_recommendations).index.tolist()# Retornamos los nombres de los items más populares\n",
    "\n",
    "def get_recommendations(user_id: int, number_max_of_recommendations: int) -> list:\n",
    "    \"\"\"Genera recomendaciones para un usuario específico, ya sea basado en usuarios similares o en los items más populares si el usuario es nuevo.\n",
    "    Args:\n",
    "        user_id (int): ID del usuario para el cual se generan recomendaciones.\n",
    "        number_max_of_recommendations (int): Número máximo de items a recomendar.\n",
    "    Returns:\n",
    "        list: Lista de nombres de items recomendados.\n",
    "    \"\"\"\n",
    "    K_NEIGHBORS = 50 # Número usuarios similares a considerar\n",
    "    if user_has_preferences(user_id): # Usuario existente con preferencias\n",
    "        user_id_str = str(user_id)\n",
    "        user_items = MATRIX_NORM.loc[user_id]\n",
    "        items_comprados = user_items[user_items.notna()].index.tolist()\n",
    "\n",
    "        # 1. OBTENCIÓN DE LA MEDIA HISTÓRICA DEL USUARIO (Corrección de la cancelación de scores)\n",
    "        # Calculamos la media del usuario objetivo a partir del DataFrame de preferencias (DF).\n",
    "        user_mean_rating = DF[DF['user_id'] == user_id]['preference_value'].mean()\n",
    "        if pd.isna(user_mean_rating):\n",
    "             # Fallback: si no se encuentra, usamos el valor neutro 3.0 (o la media global)\n",
    "            user_mean_rating = 3.0 \n",
    "        \n",
    "        similar_users = (\n",
    "            USER_SIMILARITY[user_id_str]\n",
    "            .sort_values(ascending=False)\n",
    "            .drop(user_id_str, errors='ignore')\n",
    "            .head(K_NEIGHBORS)\n",
    "        )\n",
    "        similar_users_ids = similar_users.index.astype(int).tolist()\n",
    "        sum_similarity = similar_users.sum()\n",
    "        \n",
    "        if similar_users.empty or sum_similarity == 0:\n",
    "            return cold_start_items_recommendations(number_max_of_recommendations)\n",
    "        \n",
    "        # ... (Resto del código para filtrar items comprados y obtener candidatos) ...\n",
    "        \n",
    "        similar_user_preferences = MATRIX_NORM.loc[similar_users_ids]\n",
    "        items_comprados_por_similares = similar_user_preferences.columns[\n",
    "            similar_user_preferences.notna().any()\n",
    "        ].tolist()\n",
    "        candidate_items = list(set(items_comprados_por_similares) - set(items_comprados))\n",
    "        \n",
    "        if not candidate_items:\n",
    "            return cold_start_items_recommendations(number_max_of_recommendations)\n",
    "        \n",
    "        candidate_matrix = similar_user_preferences[candidate_items].copy()\n",
    "        \n",
    "        # 2. CÁLCULO DE LA PREDICCIÓN AJUSTADA (La lógica crítica)\n",
    "        weighted_scores = candidate_matrix.multiply(similar_users, axis=0)\n",
    "        \n",
    "        # Numerador: Suma ponderada de las desviaciones (scores normalizados)\n",
    "        numerator = weighted_scores.fillna(0).sum(axis=0)\n",
    "\n",
    "        # Denominador: Suma de Similitudes\n",
    "        # sum_similarity ya está calculado.\n",
    "        \n",
    "        # Fórmula corregida: Suma Ponderada Ajustada (Deviation + User Mean)\n",
    "        deviation = numerator / sum_similarity\n",
    "        recommendation_scores = user_mean_rating + deviation \n",
    "        \n",
    "        # 3. Post-procesamiento\n",
    "        # Aseguramos que las puntuaciones estén dentro del rango de calificación (1 a 5)\n",
    "        recommendation_scores = recommendation_scores.clip(lower=1.0, upper=5.0) \n",
    "\n",
    "        recomendaciones_ordenadas = recommendation_scores.sort_values(ascending=False)\n",
    "        return recomendaciones_ordenadas.head(number_max_of_recommendations).index.tolist()\n",
    "        \n",
    "    else:\n",
    "        # Usuario nuevo sin preferencias\n",
    "        return cold_start_items_recommendations(number_max_of_recommendations)\n",
    "    \n",
    "# Ejemplo de uso de la función de recomendaciones\n",
    "user_id = 350\n",
    "get_recommendations(user_id, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ejemplo de uso de la función de recomendaciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Items recomendados para el usuario 350: ['La Vida en Marte', 'Guía de Inversión Inteligente', 'Yoga Aéreo', 'La Balada del Viajero', 'Manual de Liderazgo Ágil', 'Recetas de la Abuela', 'Microeconomía Aplicada', 'La Conquista del Espacio', 'Repostería Francesa', 'Desarrollo de Videojuegos Unity']\n"
     ]
    }
   ],
   "source": [
    "user_id = 350\n",
    "recommendations = get_recommendations(user_id, 10)\n",
    "print(f\"Items recomendados para el usuario {user_id}: {recommendations}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estrategia de Evaluación del modelo\n",
    "Levaremos a cabo los siguientes pasos:\n",
    "\n",
    "1. Separar el DataFrame de preferencias en conjuntos de entrenamiento y prueba.\n",
    "\n",
    "2. Recalcular las matrices solo con los datos de entrenamiento.\n",
    "\n",
    "3. Definimos una función de evaluación que itere sobre el conjunto de prueba, use nuestro sistema de recomendación para generar predicciones y calcule las métricas de las mismas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.Separación del DataFrame de preferencias en conjuntos de entrenamiento y prueba.\n",
    "Para dividir el Dataframe de preferencias en train y test usamos el método holdout, que selecciona las últimas k interacciones de cada usuario para el conjunto de prueba. \n",
    "Seleccionamos este método porque es simple y efectivo para evaluar sistemas de recomendación, debido a que refleja escenarios del mundo real donde queremos predecir futuras interacciones basadas en el historial pasado. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_dataframe(df_full, k_holdout)-> tuple:\n",
    "    \"\"\"Divide el DataFrame completo en conjuntos de entrenamiento y prueba utilizando el método holdout. Este método selecciona las últimas k interacciones de cada usuario para el conjunto de prueba.\n",
    "    Args:\n",
    "        df_full (pd.DataFrame): DataFrame completo con las interacciones de usuario-item.\n",
    "        k_holdout (int): Número de interacciones por usuario a incluir en el conjunto de prueba.\n",
    "    Returns:\n",
    "        tuple: (train, test) donde 'train' es el conjunto de entrenamiento y 'test' es el conjunto de prueba.\n",
    "    \"\"\"\n",
    "   #también podríamos usar sklearn.model_selection.GroupShuffleSplit para hacer el split por usuario \n",
    "    \n",
    "    test = df_full.groupby('user_id').tail(k_holdout).copy()\n",
    "    train = df_full.drop(test.index).copy()\n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.Recalculamos las matrices solo con los datos de entrenamiento.\n",
    "Recalculamos las matrices usuario-item y de similitud solo con los datos de entrenamiento, y preparamos el conjunto de prueba. \n",
    "Esto es necesario para evaluar el sistema recomendador, ya que no podemos usar datos de prueba para generar recomendaciones.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_matrices_for_evaluation(df_full, k_holdout):\n",
    "    \"\"\"\n",
    "    calcula las matrices solo con los datos de entrenamiento y prepara el conjunto de prueba.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Separamos el DataFrame en conjuntos de entrenamiento y prueba usando la función definida antes\n",
    "    train_df, test_set = split_dataframe(df_full, k_holdout)\n",
    "    # Contrucción de la matriz usuario-item solo con los datos de entrenamiento\n",
    "    matrix = train_df.pivot_table(index='user_id', columns='name', values='preference_value')\n",
    "    \n",
    "    # Normalizamos la matriz\n",
    "    user_item_matrix = matrix.copy()\n",
    "    row_mean = user_item_matrix.mean(axis=1)\n",
    "    row_std = user_item_matrix.std(axis=1)\n",
    "    row_std[row_std == 0] = 1 \n",
    "    matrix_norm_train = user_item_matrix.sub(row_mean, axis=0).div(row_std, axis=0)\n",
    "    \n",
    "    # Calculamos la similitud entre usuarios en el conjunto de entrenamiento\n",
    "    user_item_matrix_filled = matrix_norm_train.fillna(0)\n",
    "    user_similarity_cosine = cosine_similarity(user_item_matrix_filled)\n",
    "    user_ids = user_item_matrix_filled.index.tolist()\n",
    "    user_similarity_train = pd.DataFrame(\n",
    "        user_similarity_cosine, \n",
    "        index=user_ids, \n",
    "        columns=user_ids\n",
    "    )\n",
    "    user_similarity_train.index = user_similarity_train.index.astype(str)\n",
    "    user_similarity_train.columns = user_similarity_train.columns.astype(str)\n",
    "    \n",
    "    # Preparamos el conjunto de prueba en formato adecuado\n",
    "    actual_items_test = (\n",
    "        test_set\n",
    "        .groupby('user_id')['name'] # Usamos el nombre del ítem, no el ID\n",
    "        .apply(set)\n",
    "    )\n",
    "    \n",
    "    return matrix_norm_train, user_similarity_train, actual_items_test, train_df, row_mean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Función de evaluación\n",
    "##### Metrica\n",
    "Para evaluar el sistema recomendador primero es necesario elegir una métrica de evaluación, nosotros usaremos Recall. \n",
    "Consideramos que esta metrica es la mas adecuada ya que mide la capacidad del sistema para recuperar items relevantes para el usuario.\n",
    "La interpretación de esta metrica es:\n",
    "De todos los ítems que al usuario realmente compró, ¿qué porcentaje de ellos fue capturado por mi lista de recomendación.\n",
    "No usamos precision porque tiene como desventaja que penaliza las recomendaciones correctas si hay muchas recomendaciones incorrectas, ya que divide el número de aciertos entre el total de recomendaciones hechas.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def calculate_metrics(recommended_items, actual_items,n):\n",
    "    \"\"\" Calcula precision, Recall y F1 Score para un usuario dado sus items recomendados y los items reales.\n",
    "    Args:\n",
    "        recommended_items (list): Lista de items recomendados.\n",
    "        actual_items (set): Conjunto de items reales\n",
    "        n (int): numero de recomendaciones\"\"\"\n",
    "    hit_items = set(recommended_items).intersection(actual_items)\n",
    "    num_hits = len(hit_items)\n",
    "    \n",
    "    precision = num_hits / n if n > 0 else 0\n",
    "    \n",
    "    if len(actual_items) > 0:\n",
    "        recall = num_hits / len(actual_items)\n",
    "    else:\n",
    "        recall = 0\n",
    "        \n",
    "    if (precision + recall) > 0:\n",
    "        f1_score = 2 * (precision * recall) / (precision + recall)\n",
    "    else:\n",
    "        f1_score = 0\n",
    "        \n",
    "    return {\n",
    "        'Precision': precision,\n",
    "        'Recall': recall,\n",
    "        'F1-Score': f1_score\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora si podemos formar la funcion de evaluacion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def evaluate_model( n_recs=10, k_holdout=1):\n",
    "  \"\"\"Evalúa el sistema recomendador usando un enfoque Holdout.\n",
    "  Args:\n",
    "    n_recs (int): Número de recomendaciones a generar por usuario.\n",
    "    k_holdout (int): Número de interacciones a reservar para el conjunto de prueba por usuario.\n",
    "  \"\"\"\n",
    "  \n",
    "  #En el programa original usabamos variables globales, ya que usamos siempre los mismos datos, aqui debemos reasignarlas localmente para la evaluación\n",
    "  # Las variables globales se reasignan localmente para la prueba\n",
    "  global MATRIX_NORM, USER_SIMILARITY, DF\n",
    "  # Guardamos una copia de las matrices originales\n",
    "  original_matrix_norm = MATRIX_NORM\n",
    "  original_user_similarity = USER_SIMILARITY\n",
    "  original_df = DF\n",
    "  \n",
    "  # Preparamos las matrices de entrenamiento y el set de prueba\n",
    "  MATRIX_NORM, USER_SIMILARITY, actual_items_test, DF, ROW_MEAN_TRAIN = prepare_matrices_for_evaluation(original_df, k_holdout)\n",
    "\n",
    "  evaluation_results = []\n",
    "  \n",
    "  for user_id, actual_set in actual_items_test.items():\n",
    "    # Verificamos que el usuario pueda ser evaluado (tiene ítems en el test set)\n",
    "    if len(actual_set) == 0:\n",
    "      continue  \n",
    "    # Ahora que sabemos que el usuario puede ser evaluado\n",
    "    # Generamos recomendaciones usando las matrices de entrenamiento\n",
    "    recommended_item_names = get_recommendations(user_id, n_recs)\n",
    "    \n",
    "    # Calculamos las metricas\n",
    "    metrics = calculate_metrics(recommended_item_names, actual_set,n_recs)\n",
    "    metrics['user_id'] = user_id\n",
    "    evaluation_results.append(metrics)\n",
    "    \n",
    "  # Restablecemos las matrices originales\n",
    "  MATRIX_NORM = original_matrix_norm\n",
    "  USER_SIMILARITY = original_user_similarity\n",
    "  DF = original_df\n",
    "  \n",
    "  # Resultado de la evaluación\n",
    "  results_df = pd.DataFrame(evaluation_results)\n",
    "  \n",
    "  print(f\"--- Resultados Promedio de la Evaluación para n={n_recs} y K-Holdout={k_holdout} ---\")\n",
    "  print(f\"Precision: {float(results_df['Precision'].mean())}\") \n",
    "  print(f\"Recall: {float(results_df['Recall'].mean())}\") \n",
    "  print(f\"F1-Score: {float(results_df['F1-Score'].mean())}\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluación del modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prueba A\n",
    "Planteamos un escenario similar al establecido por defecto en la especificado en la documentacion de la API y un holdout moderado.\n",
    "Oculta dos interacciones recientes.\n",
    "n=5\n",
    "k=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Resultados Promedio de la Evaluación para n=5 y K-Holdout=2 ---\n",
      "Precision: 0.019714285714285715\n",
      "Recall: 0.04928571428571429\n",
      "F1-Score: 0.028163265306122457\n"
     ]
    }
   ],
   "source": [
    "evaluate_model(5, 2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prueba B\n",
    "Esta prueba se enfoca en asegurar que las primeras recomendaciones que ve el usuario son dealta calidad, utilizando una lista muy corta.\n",
    "n=3\n",
    "k=4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Resultados Promedio de la Evaluación para n=3 y K-Holdout=4 ---\n",
      "Precision: 0.06047619047619047\n",
      "Recall: 0.04535714285714286\n",
      "F1-Score: 0.05183673469387756\n"
     ]
    }
   ],
   "source": [
    "evaluate_model(3, 4)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prueba C\n",
    "Esta prueba mide el potencial máximo de su modelo para encontrar ítems relevantes.\n",
    "Utilizamos un N mucho mayor que K\n",
    "n=15\n",
    "k=3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Resultados Promedio de la Evaluación para n=10 y K-Holdout=3 ---\n",
      "Precision: 0.052571428571428575\n",
      "Recall: 0.17523809523809522\n",
      "F1-Score: 0.08087912087912087\n"
     ]
    }
   ],
   "source": [
    "evaluate_model(10, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --- CONSTANTES GLOBALES (Necesitas definir DB_NAME, USERS_URL, ITEMS_URL, PREFERENCES_URL, y split_dataframe) ---\n",
    "# DB_NAME, USERS_URL, ITEMS_URL, PREFERENCES_URL deben estar definidos fuera de este bloque.\n",
    "# K_NEIGHBORS es el valor óptimo que encontramos en las pruebas.\n",
    "K_NEIGHBORS = 10\n",
    "\n",
    "# Declaración de variables globales que serán asignadas en initial_load()\n",
    "DF = None\n",
    "MATRIX_NORM = None\n",
    "ITEM_SIMILARITY = None # <-- CAMBIO: De USER_SIMILARITY a ITEM_SIMILARITY\n",
    "USERS_DF = None\n",
    "ITEMS_DF = None\n",
    "row_mean = None \n",
    "# ------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "def initialize_db():\n",
    "    \"\"\"\n",
    "    Crea y puebla la base de datos SOLO si el archivo DB no existe.\n",
    "    Establece las claves primarias (compuestas) y foráneas.\n",
    "    \"\"\"\n",
    "    # ... (Cuerpo de la función initialize_db sin cambios) ...\n",
    "    try:\n",
    "        # Cargamos los datos desde los CSV\n",
    "        users_df = pd.read_csv(USERS_URL)\n",
    "        items_df = pd.read_csv(ITEMS_URL)\n",
    "        preferences_df = pd.read_csv(PREFERENCES_URL)\n",
    "        \n",
    "        # Preprocesamos los atributos de USERS\n",
    "        if 'id' not in users_df.columns: \n",
    "            id_cols = [col for col in users_df.columns if 'id' in col.lower()]\n",
    "            if id_cols:\n",
    "                users_df = users_df.rename(columns={id_cols[0]: 'id'})\n",
    "        \n",
    "        BASE_KEYS = ['id', 'username']\n",
    "        # Función para serializar atributos adicionales a JSON\n",
    "        def serialize_attributes(row):\n",
    "            attributes = {\n",
    "                k: v for k, v in row.items() \n",
    "                if k not in BASE_KEYS and pd.notna(v)\n",
    "            }\n",
    "            return json.dumps(attributes)# Serializamos a JSON\n",
    "        \n",
    "        \n",
    "        users_df['attributes'] = users_df.apply(serialize_attributes, axis=1)# Creamos la columna 'attributes' con JSON\n",
    "        users_df_clean = users_df[BASE_KEYS + ['attributes']].copy()# Filtramos solo las columnas necesarias         \n",
    "        \n",
    "        # Preprocesamiento de ITEMS \n",
    "        if 'id' in items_df.columns and 'item_id' not in items_df.columns:\n",
    "            items_df.rename(columns={'id': 'item_id'}, inplace=True)\n",
    "            \n",
    "        BASE_ITEM_KEYS = ['item_id', 'name']\n",
    "        def serialize_item_attributes(row):\n",
    "            attributes = {\n",
    "                k: v for k, v in row.items() \n",
    "                if k not in BASE_ITEM_KEYS and pd.notna(v)\n",
    "            }\n",
    "            return json.dumps(attributes)\n",
    "        \n",
    "        items_df['attributes'] = items_df.apply(serialize_item_attributes, axis=1)\n",
    "        items_df_clean = items_df[BASE_ITEM_KEYS + ['attributes']].copy()\n",
    "\n",
    "        # Mapeo y Filtrado de PREFERENCES \n",
    "        # Aseguramos que las columnas tengan los nombres correctos\n",
    "        preferences_df.rename(columns={\n",
    "            'user_id': 'user_id',\n",
    "            'item_id': 'item_id',\n",
    "            'preference_value': 'preference_value'\n",
    "        }, inplace=True)\n",
    "        \n",
    "        # Filtramos solo las columnas necesarias \n",
    "        preferences_df = preferences_df[['user_id', 'item_id', 'preference_value']].copy()\n",
    "        \n",
    "        # Aseguramos que ITEMS tenga 'item_id'\n",
    "        # Asumiendo que el CSV de Items usa 'item_id'\n",
    "        if 'id' in items_df.columns and 'item_id' not in items_df.columns:\n",
    "            items_df.rename(columns={'id': 'item_id'}, inplace=True)\n",
    "            \n",
    "        # ------------------------------------------------------------------------------------------------\n",
    "        # Creación de la base de datos SQLite y tablas con claves primarias y foráneas\n",
    "        # ------------------------------------------------------------------------------------------------\n",
    "        conn = sqlite3.connect(DB_NAME)# Conexión a la base de datos SQLite\n",
    "        cursor = conn.cursor()# Cursor para ejecutar comandos SQL\n",
    "        \n",
    "       #Creamos tabla de usuarios con id como PRIMARY KEY y username único\n",
    "        cursor.execute(\"\"\"\n",
    "             CREATE TABLE IF NOT EXISTS users (\n",
    "                 id INTEGER PRIMARY KEY NOT NULL,\n",
    "                 username TEXT UNIQUE NOT NULL,\n",
    "                 attributes TEXT\n",
    "             );\n",
    "        \"\"\")\n",
    "        \n",
    "        # Creamos la tabla de items con item_id como PRIMARY KEY\n",
    "        cursor.execute(\"\"\"\n",
    "                 CREATE TABLE IF NOT EXISTS items (\n",
    "                     item_id INTEGER PRIMARY KEY NOT NULL,\n",
    "                     name TEXT NOT NULL,\n",
    "                     attributes TEXT\n",
    "                 );\n",
    "             \"\"\")\n",
    "        \n",
    "        #Creamos la tabla de preferencias con claves foráneas a las tablas users e items y clave primaria compuesta\n",
    "        cursor.execute(\"\"\"\n",
    "            CREATE TABLE IF NOT EXISTS preferences (\n",
    "                user_id INTEGER NOT NULL,\n",
    "                item_id INTEGER NOT NULL,\n",
    "                preference_value INTEGER NOT NULL,\n",
    "                PRIMARY KEY (user_id, item_id),\n",
    "                FOREIGN KEY(user_id) REFERENCES users(id) ON DELETE CASCADE,\n",
    "                FOREIGN KEY(item_id) REFERENCES items(item_id) ON DELETE CASCADE\n",
    "            );\n",
    "        \"\"\")\n",
    "        \n",
    "        #  Deshabilitamos la verificación de FK temporalmente (solo para carga inicial) para evitar errores de inserción\n",
    "        conn.execute(\"PRAGMA foreign_keys = OFF;\") \n",
    "\n",
    "        # Insertamos los datos en las tablas correspondientes\n",
    "        users_df_clean.to_sql('users', conn, if_exists='append', index=False)\n",
    "        items_df_clean.to_sql('items', conn, if_exists='append', index=False) \n",
    "        preferences_df.to_sql('preferences', conn, if_exists='append', index=False)\n",
    "        \n",
    "        # Volvemos a habilitar la verificación de claves foráneas\n",
    "        conn.execute(\"PRAGMA foreign_keys = ON;\")\n",
    "        \n",
    "        conn.commit()# Guardamos los cambios\n",
    "        conn.close()# Cerramos la conexión\n",
    "        \n",
    "        print(f\" Base de datos SQLite creada y cargada con éxito.\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\" Error al inicializar SQLite: {e}\")\n",
    "        raise\n",
    "\n",
    "\n",
    "def initial_load():\n",
    "    \"\"\"Carga los datos de SQLite y genera las matrices necesarias para el sistema recomendador IBCF.\n",
    "    Returns:\n",
    "        tuple: (df, matrix_norm, item_similarity, users_df, items_df, row_mean)\"\"\"\n",
    "    if not(os.path.exists(DB_NAME)): # Verificamos si la base de datos ya existe\n",
    "        print(f\"Base de datos '{DB_NAME}' no encontrada. Creandola e inicializándola...\")\n",
    "        initialize_db() #Inicializa la DB si no existe\n",
    "    \n",
    "    # Consulta SQL para unir items y preferences\n",
    "    SQL_QUERY = \"\"\"\n",
    "SELECT \n",
    "    T1.item_id,\n",
    "    T1.name,\n",
    "    T2.user_id,\n",
    "    T2.preference_value\n",
    "FROM \n",
    "    items AS T1 \n",
    "INNER JOIN \n",
    "    preferences AS T2\n",
    "ON \n",
    "    T1.item_id = T2.item_id;\n",
    "\"\"\"\n",
    "    \n",
    "    conn = sqlite3.connect(DB_NAME)# Abrimos la conexión a la base de datos\n",
    "    df = pd.read_sql_query(SQL_QUERY, conn)# Leemos las preferencias uniendo items y preferences\n",
    "    users_df = pd.read_sql_query(\"SELECT id, username, attributes FROM users\", conn)# Leemos los usuarios desde la base de datos\n",
    "    items_df = pd.read_sql_query(\"SELECT * FROM items\", conn)# Leemos los items desde la base de datos\n",
    "    conn.close()# Cerramos la conexión a la base de datos\n",
    "\n",
    "    # ... (Deserialización de atributos sin cambios) ...\n",
    "    if 'attributes' in users_df.columns:\n",
    "        users_df['attributes'] = users_df['attributes'].apply(\n",
    "            lambda x: json.loads(x) if pd.notna(x) and isinstance(x, str) else {}\n",
    "        )\n",
    "    if 'attributes' in items_df.columns:\n",
    "        items_df['attributes_dict'] = items_df['attributes'].apply(\n",
    "            lambda x: json.loads(x) if pd.notna(x) and isinstance(x, str) else {}\n",
    "        )\n",
    "        temp_attr_df = items_df['attributes_dict'].apply(pd.Series)\n",
    "        items_df = pd.concat([items_df, temp_attr_df], axis=1)\n",
    "    if 'id' in users_df.columns: \n",
    "        users_df['id'] = users_df['id'].astype(int)\n",
    "\n",
    "    # Creamos las matrices necesarias para el sistema recomendador\n",
    "    matrix = df.pivot_table(index='user_id', columns='name', values='preference_value')# Matriz usuario-item\n",
    "    user_item_matrix = matrix.copy()\n",
    "    row_mean = user_item_matrix.mean(axis=1)# Promedio por fila (media de usuario)\n",
    "    row_std = user_item_matrix.std(axis=1)\n",
    "    row_std[row_std == 0] = 1 \n",
    "    matrix_norm = user_item_matrix.sub(row_mean, axis=0).div(row_std, axis=0)# Normalizamos por usuario\n",
    "\n",
    "    # --- CAMBIO CLAVE: CÁLCULO DE SIMILITUD ENTRE ÍTEMS ---\n",
    "    item_item_matrix_filled = matrix_norm.fillna(0).T # Transponemos la matriz normalizada\n",
    "    item_similarity_cosine = cosine_similarity(item_item_matrix_filled) # Calculamos similitud entre ítems\n",
    "    item_names = item_item_matrix_filled.index.tolist()\n",
    "    item_similarity = pd.DataFrame( # Creamos la matriz de similitud de ítems\n",
    "        item_similarity_cosine, \n",
    "        index=item_names, \n",
    "        columns=item_names\n",
    "    )\n",
    "    item_similarity.index = item_similarity.index.astype(str)\n",
    "    item_similarity.columns = item_similarity.columns.astype(str)\n",
    "    # -----------------------------------------------------\n",
    "\n",
    "    # Retornamos los datos procesados (USER_SIMILARITY reemplazado por ITEM_SIMILARITY)\n",
    "    return df, matrix_norm, item_similarity, users_df, items_df,row_mean\n",
    "\n",
    "try:\n",
    "    # --- CAMBIO DE ASIGNACIÓN GLOBAL ---\n",
    "    DF, MATRIX_NORM, ITEM_SIMILARITY, USERS_DF, ITEMS_DF, row_mean = initial_load()\n",
    "    # ----------------------------------\n",
    "except Exception as e:\n",
    "    print(f\" ERROR FATAL: La aplicación no pudo iniciar debido al error de carga/procesamiento: {e}\")\n",
    "\n",
    "\n",
    "def user_has_preferences(user_id: int) -> bool:\n",
    "    \"\"\"Verifica si un usuario tiene preferencias registradas en la matriz normalizada.\"\"\"\n",
    "    return user_id in MATRIX_NORM.index\n",
    "\n",
    "def cold_start_items_recommendations(number_max_of_recommendations: int) -> list: \n",
    "    \"\"\"Genera recomendaciones para usuarios nuevos basadas en los items más populares.\"\"\"\n",
    "    top_items = DF.groupby('name')['preference_value'].count().sort_values(ascending=False)\n",
    "    return top_items.head(number_max_of_recommendations).index.tolist()\n",
    "\n",
    "def get_recommendations(user_id: int, number_max_of_recommendations: int) -> list:\n",
    "    \"\"\"Genera recomendaciones IBCF para un usuario específico.\"\"\"\n",
    "    if user_has_preferences(user_id):\n",
    "        # ... (cálculo de user_mean_rating y user_ratings_norm sin cambios) ...\n",
    "        \n",
    "        user_mean_rating = DF[DF['user_id'] == user_id]['preference_value'].mean()\n",
    "        if pd.isna(user_mean_rating):\n",
    "             user_mean_rating = 3.0 \n",
    "        \n",
    "        user_ratings_norm = MATRIX_NORM.loc[user_id].dropna()\n",
    "        items_rated_by_user = user_ratings_norm.index.tolist()\n",
    "        \n",
    "        # --- CAMBIO CRÍTICO: FILTRADO DE ÍTEMS CANDIDATOS PARA EVITAR BLOQUEOS ---\n",
    "        \n",
    "        # 1. Obtener los K ítems más populares no calificados. (Filtrado por popularidad global)\n",
    "        # Esto reduce drásticamente el tamaño del bucle \"for\"\n",
    "        top_unrated_globally = DF[~DF['name'].isin(items_rated_by_user)] \\\n",
    "            .groupby('name')['preference_value'].count() \\\n",
    "            .sort_values(ascending=False).head(300).index.tolist() # Limitar a 300 candidatos\n",
    "            \n",
    "        candidate_items = list(set(top_unrated_globally))\n",
    "        \n",
    "        # --- FIN DEL CAMBIO CRÍTICO ---\n",
    "        \n",
    "        if not candidate_items:\n",
    "            return cold_start_items_recommendations(number_max_of_recommendations)\n",
    "\n",
    "        # ... (El resto del código del bucle 'for' sigue igual) ...\n",
    "        \n",
    "        recommendation_scores = {}\n",
    "        for candidate_item in candidate_items:\n",
    "            \n",
    "            # --- Lógica de predicción IBCF ---\n",
    "            # ... (cuerpo del bucle sin cambios) ...\n",
    "            \n",
    "            if candidate_item not in ITEM_SIMILARITY.index:\n",
    "                continue\n",
    "            item_similarity_vector = ITEM_SIMILARITY.loc[candidate_item]\n",
    "            \n",
    "            rated_items_similarity = item_similarity_vector[items_rated_by_user]\n",
    "            final_ratings = user_ratings_norm[items_rated_by_user]\n",
    "            \n",
    "            if K_NEIGHBORS > 0:\n",
    "                neighbor_data = pd.DataFrame({\n",
    "                    'similarity': rated_items_similarity,\n",
    "                    'rating': final_ratings\n",
    "                }).dropna()\n",
    "                \n",
    "                top_neighbors = neighbor_data['similarity'].abs().sort_values(ascending=False).head(K_NEIGHBORS).index\n",
    "                \n",
    "                final_similarity = rated_items_similarity[top_neighbors]\n",
    "                final_ratings = final_ratings[top_neighbors]\n",
    "\n",
    "            numerator = (final_similarity * final_ratings).sum()\n",
    "            denominator = final_similarity.abs().sum()\n",
    "            \n",
    "            if denominator > 0:\n",
    "                deviation = numerator / denominator\n",
    "                prediction = user_mean_rating + deviation\n",
    "                recommendation_scores[candidate_item] = prediction\n",
    "                \n",
    "        # ... (Post-procesamiento sin cambios) ...\n",
    "        \n",
    "        recommendation_scores_series = pd.Series(recommendation_scores)\n",
    "        \n",
    "        if recommendation_scores_series.empty:\n",
    "            return cold_start_items_recommendations(number_max_of_recommendations)\n",
    "            \n",
    "        recommendation_scores_series = recommendation_scores_series.clip(lower=1.0, upper=5.0) \n",
    "\n",
    "        recomendaciones_ordenadas = recommendation_scores_series.sort_values(ascending=False)\n",
    "        return recomendaciones_ordenadas.head(number_max_of_recommendations).index.tolist()\n",
    "        \n",
    "    else:\n",
    "        return cold_start_items_recommendations(number_max_of_recommendations)\n",
    "\n",
    "# --- FUNCIONES DE EVALUACIÓN (Modificadas para usar ITEM_SIMILARITY) ---\n",
    "\n",
    "def prepare_matrices_for_evaluation(df_full, k_holdout):\n",
    "    \"\"\"\n",
    "    Calcula las matrices de entrenamiento para IBCF y prepara el conjunto de prueba.\n",
    "    \"\"\"\n",
    "    # ... (Asumimos split_dataframe existe y funciona)\n",
    "    train_df, test_set = split_dataframe(df_full, k_holdout)\n",
    "    matrix = train_df.pivot_table(index='user_id', columns='name', values='preference_value')\n",
    "    \n",
    "    # Normalizamos la matriz\n",
    "    user_item_matrix = matrix.copy()\n",
    "    row_mean = user_item_matrix.mean(axis=1)\n",
    "    row_std = user_item_matrix.std(axis=1)\n",
    "    row_std[row_std == 0] = 1 \n",
    "    matrix_norm_train = user_item_matrix.sub(row_mean, axis=0).div(row_std, axis=0)\n",
    "    \n",
    "    # --- CAMBIO CLAVE: CÁLCULO DE SIMILITUD ENTRE ÍTEMS (ENTRENAMIENTO) ---\n",
    "    item_item_matrix_filled_train = matrix_norm_train.fillna(0).T\n",
    "    item_similarity_cosine_train = cosine_similarity(item_item_matrix_filled_train)\n",
    "    item_names_train = item_item_matrix_filled_train.index.tolist()\n",
    "    item_similarity_train = pd.DataFrame(\n",
    "        item_similarity_cosine_train, \n",
    "        index=item_names_train, \n",
    "        columns=item_names_train\n",
    "    )\n",
    "    item_similarity_train.index = item_similarity_train.index.astype(str)\n",
    "    item_similarity_train.columns = item_similarity_train.columns.astype(str)\n",
    "    # ---------------------------------------------------------------------\n",
    "    \n",
    "    actual_items_test = (\n",
    "        test_set\n",
    "        .groupby('user_id')['name']\n",
    "        .apply(set)\n",
    "    )\n",
    "    \n",
    "    # Retorna item_similarity_train\n",
    "    return matrix_norm_train, item_similarity_train, actual_items_test, train_df, row_mean,\n",
    "\n",
    "def calculate_metrics(recommended_items, actual_items,n):\n",
    "    \"\"\" Calcula precision, Recall y F1 Score para un usuario dado.\"\"\"\n",
    "    # ... (Cuerpo de la función sin cambios) ...\n",
    "    hit_items = set(recommended_items).intersection(actual_items)\n",
    "    num_hits = len(hit_items)\n",
    "    \n",
    "    precision = num_hits / n if n > 0 else 0\n",
    "    \n",
    "    if len(actual_items) > 0:\n",
    "        recall = num_hits / len(actual_items)\n",
    "    else:\n",
    "        recall = 0\n",
    "        \n",
    "    if (precision + recall) > 0:\n",
    "        f1_score = 2 * (precision * recall) / (precision + recall)\n",
    "    else:\n",
    "        f1_score = 0\n",
    "        \n",
    "    return {\n",
    "        'Precision': precision,\n",
    "        'Recall': recall,\n",
    "        'F1-Score': f1_score\n",
    "    }\n",
    "def evaluate_model( n_recs=10, k_holdout=1):\n",
    "    \"\"\"Evalúa el sistema recomendador usando un enfoque Holdout para IBCF.\"\"\"\n",
    "    \n",
    "    # Las variables globales se reasignan localmente para la prueba\n",
    "    global MATRIX_NORM, ITEM_SIMILARITY, DF # <-- CAMBIO: ITEM_SIMILARITY\n",
    "    # Guardamos una copia de las matrices originales\n",
    "    original_matrix_norm = MATRIX_NORM\n",
    "    original_item_similarity = ITEM_SIMILARITY # <-- CAMBIO: ITEM_SIMILARITY\n",
    "    original_df = DF\n",
    "    \n",
    "    # Preparamos las matrices de entrenamiento y el set de prueba\n",
    "    MATRIX_NORM, ITEM_SIMILARITY, actual_items_test, DF, ROW_MEAN_TRAIN = prepare_matrices_for_evaluation(original_df, k_holdout)\n",
    "\n",
    "    evaluation_results = []\n",
    "    \n",
    "    for user_id, actual_set in actual_items_test.items():\n",
    "        if len(actual_set) == 0:\n",
    "            continue  \n",
    "        \n",
    "        # Generamos recomendaciones usando las matrices de entrenamiento IBCF\n",
    "        recommended_item_names = get_recommendations(user_id, n_recs)\n",
    "        \n",
    "        # Calculamos las metricas\n",
    "        metrics = calculate_metrics(recommended_item_names, actual_set,n_recs)\n",
    "        metrics['user_id'] = user_id\n",
    "        evaluation_results.append(metrics)\n",
    "        \n",
    "    # Restablecemos las matrices originales\n",
    "    MATRIX_NORM = original_matrix_norm\n",
    "    ITEM_SIMILARITY = original_item_similarity # <-- CAMBIO: ITEM_SIMILARITY\n",
    "    DF = original_df\n",
    "    \n",
    "    # Resultado de la evaluación\n",
    "    results_df = pd.DataFrame(evaluation_results)\n",
    "    \n",
    "    print(f\"--- Resultados Promedio de la Evaluación para n={n_recs} y K-Holdout={k_holdout} ---\")\n",
    "    print(f\"Precision: {float(results_df['Precision'].mean())}\") \n",
    "    print(f\"Recall: {float(results_df['Recall'].mean())}\") \n",
    "    print(f\"F1-Score: {float(results_df['F1-Score'].mean())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Resultados Promedio de la Evaluación para n=10 y K-Holdout=3 ---\n",
      "Precision: 0.05785714285714286\n",
      "Recall: 0.19285714285714287\n",
      "F1-Score: 0.08901098901098901\n"
     ]
    }
   ],
   "source": [
    "evaluate_model(10, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Escultura Moderna',\n",
       " 'Negociación y Persuasión',\n",
       " 'Cuentos Breves de Otoño',\n",
       " 'Cocina Mexicana Auténtica',\n",
       " 'Manual de Liderazgo Ágil',\n",
       " 'El Silencio del Testigo',\n",
       " 'La Venganza del Inspector',\n",
       " 'Algoritmos Avanzados en Java',\n",
       " 'Mundo Virtual 3.0',\n",
       " 'Recetas de la Abuela']"
      ]
     },
     "execution_count": 277,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_recommendations(350, 10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
